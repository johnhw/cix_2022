{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Theory and practice\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "You will understand:\n",
    "\n",
    "* What a Bayesian is.\n",
    "* The idea of a data generating process;\n",
    "* The relation of models and parameters;\n",
    "* What uncertainty is, where it comes from, and why it is important;\n",
    "* The evolution of probabilistic programming languages;\n",
    "* What probability is and how it represents uncertainty;\n",
    "* The distinction between prediction and inference and the relation to forward and inverse probability.\n",
    "* A high-speed review of basic probability theory through code: \n",
    "    * axioms of probability\n",
    "    * mass functions, distributions, random variables\n",
    "    * likelihood and sampling\n",
    "    * joint, marginal, conditional, Bayes' rule\n",
    "    * entropy, divergence\n",
    "* Major classes of inference algorithms\n",
    "\n",
    "## Poll\n",
    "\n",
    "## What are Bayesian methods?\n",
    "\n",
    "A Bayesian is someone who:\n",
    "\n",
    "* Is happy to live without truth;\n",
    "* Reasons from belief to belief, guided by evidence;\n",
    "* Thinks backwards by thinking forwards.\n",
    "\n",
    "### Without truth\n",
    "\n",
    "### Belief to belief\n",
    "\n",
    "### Forwards, not back\n",
    "\n",
    "\n",
    "## Models: Data generating processes\n",
    "Let's get back to computational interaction. We need *models* to do computational interaction, and they need to be *executable*. That means code that simulates or emulates some interaction\n",
    "element of interest. At the heart of Bayesian modelling we have the idea of a **data generating process**, a process which we believe is generating data we observe.\n",
    "\n",
    "[Image]\n",
    "\n",
    "\n",
    "\n",
    "### The advance of programming languages\n",
    "\n",
    "Advances in programming languages change the way we express models, and implicitly how we think about modelling the world. A model can be written as a *function*.\n",
    "\n",
    "#### Traditional: Python, C, Java, Rust, C#, ...\n",
    "We express models as operations on primitives, like numbers.\n",
    "\n",
    "```python\n",
    "def f(x):\n",
    "    return x ** 2 + x - 2 \n",
    "```\n",
    "\n",
    "#### Vectorised: NumPy, eigen, Julia, ...\n",
    "We express models directly over numerical arrays (\"tensors\"). Code gets shorter, cleaner, and more efficient, takes advantage of hardware, etc.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "def f(x):\n",
    "    return np.sum(x**2 + x - 2, axis=1)\n",
    "```\n",
    "\n",
    "### Differentiable: autograd, JAX, PyTorch, TensorFlow, ...\n",
    "Defining a function over numerical arrays *automatically* also defines a function returning the partial derivatives. Universal first-order optimisation (gradient descent) becomes available.\n",
    "\n",
    "* *Now we can write **inverse programs**: we define the output, and solve for the input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as anp\n",
    "import autograd\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return anp.sum((x**2 + x - 2) ** 2, axis=1)\n",
    "\n",
    "\n",
    "df = autograd.elementwise_grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = anp.eye(4)\n",
    "print(f(x))\n",
    "print(df(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if only we had some way of repeating\n",
    "# things on a computer\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Probabilistic (PPLs): Stan, PyMC, Turing.jl, BUGS/JAGS, ...\n",
    "This adds distributions to programs. It automatically includes *random simulation*, *likelihood* and most importantly *inference*.\n",
    "\n",
    "We don't need a PPL to do random simulation (a **stochastic model**):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "\n",
    "# forward: random simulation\n",
    "def f(x):\n",
    "    x = np.array(x)\n",
    "    y = np.random.normal(0, 1, x.shape)\n",
    "    return x**2 + x - 2 + y\n",
    "\n",
    "\n",
    "# different on every run\n",
    "# models variation in the world\n",
    "f([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or to do the inverse; compute the likelihood of (stochastic) observations under a parameterised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llik_f(x, y):\n",
    "    x = np.array(x)\n",
    "    # return log-lik of observations y under model settings x\n",
    "    return np.sum(ss.norm(x**2 + x - 2, 1).logpdf(y))\n",
    "\n",
    "\n",
    "print(llik_f([1, 2, 3], f([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but to do the **inference** part -- to work out the relative probability of possible inputs that might have generated an observation -- we'd be much better off using a real probabilistic programming language. This will implement efficient algorithm to allow us to write **uncertain inverse programs**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parameters and models\n",
    "\n",
    "## Uncertainty\n",
    "\n",
    ">    All theorems are true.  \n",
    ">    All models are wrong.  \n",
    ">    And all data are inaccurate.  \n",
    ">    What are we to do?  \n",
    ">    We must be sure to remain uncertain. \n",
    "\n",
    "-- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* \n",
    "\n",
    "#### What is uncertainty and where does it come from?\n",
    "\n",
    "\n",
    "## What is a Bayesian [II]?\n",
    "\n",
    "A Bayesian:\n",
    "\n",
    "* Represents, preserves and manipulates uncertainty about unknown states. Uncertainty is **first-class**.\n",
    "* Builds generative models of the phenomena under consideration, that simulate plausible observations.\n",
    "* Reasons about the unknown parameters that modulate the behaviour of those generative models.\n",
    "\n",
    "\n",
    "## Probability\n",
    "\n",
    "\n",
    "\n",
    "### What is probability?\n",
    "\n",
    "A fraught philosophical question! See the references for debates on this topic. We'll make some uncontroversial statements, then an *interpretation* of probability.\n",
    "\n",
    "**Probability, as we shall use it, is simply an extension of ordinary logic to uncertain situations.**\n",
    "\n",
    "\n",
    "#### Basic facts\n",
    "\n",
    "* We associate numbers (probabilities) with sets (*events*), written $P(A)$to mean \"probability of event A\".\n",
    "* Probabilities are non-negative and cannot exceed 1: $0 \\leq P(A) \\leq 1$ \n",
    "* A probability distribution associates a set of distinct *outcomes* to probabilities. $P(X=x)$ meaning the probability that variable $X$ takes on outcome $x$.\n",
    "* An *event* is any set of outcomes.\n",
    "* The probability of all possible outcomes in a distribution sums to 1 exactly.\n",
    "* The probability of any set of disjoint events that cover all outcomes is therefore also 1.\n",
    "* => If A and B are events $P(A \\lor B) = P(A) + P(B) - P(A\\land B)$ (sum rule; A and B are sets of outcomes)\n",
    "* => If A has probability $P(A)=P(X \\in A)$, $P(Â¬A)=P(X \\notin A)=1-P(A)$\n",
    "* The probability of two *independent* events A and B is $P(A \\land B) = P(A)P(B)$\n",
    "* The probability of A *given we know that* an event B is true is written $P(A|B) = P(A \\land B)/P(B)$\n",
    "* The probability of P(A|B) is **not** in general P(B|A).\n",
    "* $P(A|B) = P(B|A)P(A) / P(B)$ (Bayes' Rule)\n",
    "* $P(B) = \\sum_B P(B|A)P(A)$ \n",
    "\n",
    "---\n",
    "\n",
    "Scenario: modelling the age of someone's bike.\n",
    "\n",
    "* The probability of a person's bike being more than 5 years old is an *event*; perhaps $P(age>5)=0.5$\n",
    "* A bike's age cannot be less likely than impossible or more likely than certain.\n",
    "* A probability distribution might map a finite range of integer ages to probabilities; real numbers in the range 0-1; perhaps $P(age=0)=0.02$,  $P(age=1)=0.2$, $P(age=3)=0.1$, etc.\n",
    "    * Note: it doesn't have to be this way; we could have a continuous age, or a discrete but infinite set of ages. The details get a bit more fiddly.\n",
    "* A bike being less than five years old $P(age<5)=P(age \\in \\{0,1,2,3,4\\})$, or being an even number of years old $P(age \\mod 2=0)=P(age \\in \\{0, 2, 4, 6, \\dots \\})$, or being 1 year old $P(age=0)=P(age \\in \\{0\\})$; these are all *events*.\n",
    "* The probability of a bike \"having\" an age is tautologically 1 in this model; so the probability of each outcome $P(age=1)+P(age=2)+P(age=3)+\\dots=1.0$\n",
    "* The probability of a bike being less than five years old *or* being equal to or more than five years old must be 1.0, by the same logic (every outcome is covered exactly once). $P(age<5) + P(age\\geq 5)=1.0$\n",
    "* The probability of a bike being less than five years old or more than three years old is: $P(age>3 | age<5) = P(age<5) + P(age>3) - P(age<5 \\land age>3)$ -- we compensate for \"double counting\" the overlap\n",
    "* The probability of a bike being an even number of years is one minus the probability of being an odd number of years: $P(age \\mod 2=0) + P(age \\mod 2=1) = 1$\n",
    "* The probability that my bike is older than ten years old and your bike is *also* older than ten years old $P(mine>10 \\land yours>10) = P(mine>10)P(yours>10)$ *assuming* we have absolutely no relation to each other\n",
    "* The probability of a bike being an even number of years old is given we know it is less than three years old: $P(age \\mod 2 = 0|age<3) = P(age \\in {0,2}) / P(age \\in {0, 1, 2}) = (P(age=0) + P(age=2)) / [P(age=0) + P(age=1) + P(age=2)]$\n",
    "\n",
    "## Random variables and distributions\n",
    "\n",
    "* A **random variable** $X$ is a variable whose value is not known, but whose possible values *are* known, and how likely those values are is also known. Probability theory allows us to manipulate random variables without having to assign them a specific value.\n",
    "* A **probability distribution** $P(X=x)$ associates a random variables outcomes to probabilities. It encodes the plausibility of a variable's outcomes.\n",
    "* A **probability mass function** $f_X(x)$ is a function that yields probabilities as a function of outcomes.\n",
    "* If we have uncountable outcomes (like real numbers), we instead use a **probability density function** $f_X(x)$, which just guarantees the rules above hold for dense subsets of the outcomes, even if they can't hold for individual outcomes.\n",
    "    * Densities are not probabilities! They are non-negative, but can be greater than 1; the *integral* of a density over some domain *is* a probability. (e.g. $P(1\\leq age \\leq 2) = \\int_1^2 f_X(age) dx$ over the interval [1, 2] of $\\mathbb{R}$) \n",
    "\n",
    "A random variable could represent:\n",
    "\n",
    "* the outcome of dice throw (discrete), i.e. over the set of outcomes $\\{1,2,3,4,5,6\\}$; \n",
    "* whether or not it is raining outside (discrete: binary), over the set of outcomes $\\{\\text{heads}, \\text{tails}\\}$; \n",
    "* the height of person we haven't met yet (continuous), over the set of outcomes $\\real$; \n",
    "* the position of a user's hand (continuous, multi-dimensional), over the set of outcomes $\\real^3$. \n",
    "\n",
    "\n",
    "## Distributions\n",
    "A **probability distribution** defines how likely different states of a random variable are. \n",
    "\n",
    "We can see $X$ as the the *experiment* and $x$ as the *outcome*, with a function mapping every possible outcome to a probability. \n",
    "\n",
    "$$P(X=x),\\  \\text{the probability of random variable X taking on value x}\\\\\n",
    "P(X),\\  \\text{shorthand for probability of X=x }\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Philosophy\n",
    "\n",
    "We will use the subjective Bayesian interpretation of probability. This has a simple statement but deep implications.\n",
    "\n",
    "* Probability is a *degree of belief*.\n",
    "* We express how strongly we believe something to be true with a probability. \n",
    "* We encode all beliefs as probability distributions. It's probabilities all the way down.\n",
    "* We manipulate all beliefs via the rules above. This naturally includes all of classical logic, where P=0 is False and P=1 is True.\n",
    "* We might expect that these probabilities would be *consistent* with observed relative frequencies of some random repeated process, but **that's not our definition of probability**. We do not invoke the mystical infinitely repeated identical experiments!\n",
    "* It's completely fine to make statements like \"the probability that it is raining right now\", \"the probability that 10^10^10-1 is prime\" or \"the probability that the 2012 Olympics was in London\" (think carefully about what the probability might be!)\n",
    "* Because this form of probability theory is merely a logic of uncertain beliefs, we must always reason from some starting point. Rather than **axioms**, as in classical logic, we instead begin from **priors**, associating beliefs to probabilities at the start of a reasoning process.\n",
    "\n",
    "## Probability mass functions and probability density functions\n",
    "\n",
    "### Inference\n",
    "\n",
    "We seek a logical process to perform inference: the deduction of the hidden from the seen. We seek to do so under uncertainty, where we do not deal in absolutes of truth and falsity.\n",
    "\n",
    "* Our primary tool is Bayes Rule. \n",
    "* The ability to do inference is derived from the ability to say: how likely is some unseen X given we saw Y?\n",
    "    * \"How likely is it that my bike is more than four years old given that it has visible corrosion?\"\n",
    "        * I can see corrosion; I can't see age.\n",
    "    * We can answer that as:\n",
    "        * It is the probability that we'd observe Y if X were true; multiplied by how likely we *already* believe X to be true; and normalised so that the probability for each possible X sums up to 1.\n",
    "        * $P(X|Y) = P(Y|X)P(X) / P(Y) = P(Y|X)P(X) / \\sum_X P(Y|X)P(X)$\n",
    "        * $P(X|Y) \\propto P(Y|X)P(X)$ if all we care about is how *relatively* likely each possible $X$ is (not how *absolutely* likely it is)\n",
    "    * These parts have names:\n",
    "        * `posterior = likelihood * prior / evidence`\n",
    "        * **posterior** The probability of beliefs about $X$ after having observed $Y$\n",
    "        * **likelihood** How likely $Y$ is to be observed under any possible hypothesised $X$\n",
    "        * **prior** How currently likely $X$ is before observing $Y$\n",
    "        * **evidence** How likely $Y$ is to be observed regardless of what hypothesis we make about $X$\n",
    "\n",
    "* The likelihood of X, written $L(X)$ is how likely $X$ is to be observed under a particular model. \n",
    "    * Probabilities speak of the \"future\", of the relative propensity for unobserved outcomes to occur.\n",
    "    * Likelihoods speak of the \"past\", of observed states. They are just a function of observations/data, and they tell us how likely observed outcomes are under some assumption.\n",
    "    * The likelihood is $L(x) = f_X(x)$, just the mass/density evaluated for a specific outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Bayesian? [III]\n",
    "\n",
    "A **Bayesian**:\n",
    "\n",
    "* Represents belief exclusively using probability distributions and conducts all computation via the logic of probability.\n",
    "* Reasons from hypotheses about the world to the evidence that those hypotheses would generate (via a data generating process).\n",
    "* Updates belief using Bayes' Rule, combining a prior belief with observed evidence to deduce new beliefs.\n",
    "* Infers conditional distributions -- posterior distributions -- over unseen parameters of the DGP.\n",
    "\n",
    "Given a parameterised simulator that approximates the problem we are interested in, and some idea about what values these parameters could take on (expressed as a prior probability distribution) we can then use evidence to make a Bayesian update to concentrate a belief distribution on more likely parameter configurations --- a posterior probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A grid model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import itertools\n",
    "\n",
    "\n",
    "class PMF:\n",
    "    def __init__(self, pmf):\n",
    "        # p: outcome -> value\n",
    "        self.pmf = pmf\n",
    "        self.outcomes = list(self.pmf.keys())\n",
    "        self.probs = list(self.pmf.values())\n",
    "\n",
    "    def __str__(self):\n",
    "        return pprint.pformat(self.pmf)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(self, outcome):\n",
    "    return self.pmf[outcome]\n",
    "\n",
    "\n",
    "PMF.likelihood = likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lik(self, outcomes):\n",
    "    return sum([np.log(self.likelihood(o)) for o in outcomes])\n",
    "\n",
    "\n",
    "PMF.log_lik = log_lik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(self, n):\n",
    "    return np.random.choice(self.outcomes, p=self.probs, size=n)\n",
    "\n",
    "\n",
    "PMF.sample = sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def from_empirical(self, observations):\n",
    "    c = Counter(observations)\n",
    "    total = sum(c.values())\n",
    "    return PMF({outcome: count / total for outcome, count in c.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect(self, g=lambda x: x):\n",
    "    return sum(g(outcome) * p for outcome, p in self.pmf.items())\n",
    "\n",
    "\n",
    "PMF.expect = expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(self):\n",
    "    return -sum(p * np.log2(p) for p in self.probs)\n",
    "\n",
    "\n",
    "PMF.entropy = entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes(self, likelihood):\n",
    "    unnorm = {k: self[k] * likelihood[k] for k in self.pmf}\n",
    "    s = sum(unnorm.values())\n",
    "    return PMF({unnorm[k] / s for k in unnorm})\n",
    "\n",
    "\n",
    "PMF.bayes = bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint(self, other):\n",
    "    return PMF(\n",
    "        {\n",
    "            (a, b): p_a * p_b\n",
    "            for (a, p_a), (b, p_b) in itertools.product(\n",
    "                self.pmf.items(), other.pmf.items()\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "PMF.__matmul__ = joint\n",
    "\n",
    "PMF({1: 0.2, 2: 0.8}) @ PMF({\"cat\": 0.1, \"dog\": 0.9})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal(self, n):\n",
    "    acc = {}\n",
    "    for outcome, p in self.pmf.items():\n",
    "        removed = outcome[:n] + outcome[n + 1 :]\n",
    "        acc[removed] = acc.get(removed, 0) + p\n",
    "    return PMF(acc)\n",
    "\n",
    "\n",
    "PMF.marginal = marginal\n",
    "\n",
    "p = PMF({1: 0.2, 2: 0.8}) @ PMF({\"cat\": 0.1, \"dog\": 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditional\n",
    "def conditional(self, n):\n",
    "    p_B = self.marginal(n)\n",
    "\n",
    "    for outcome, p in self.pmf.items():\n",
    "        p / p_B.pmf[outcome[n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Inference approaches\n",
    "\n",
    "### The process of eliciting, encoding and validating\n",
    "\n",
    "#### Elicit and encode\n",
    "\n",
    "#### Validate\n",
    "\n",
    "\n",
    "### Concrete algorithms\n",
    "\n",
    "#### MCMC\n",
    "\n",
    "#### Variational\n",
    "\n",
    "#### Exact\n",
    "\n",
    "## What is a Bayesian [IV]\n",
    "\n",
    "### Why is this Computational HCI?\n",
    "\n",
    "* We build **statistical models** of user behaviour, and estimate parameters of that model from quantitative observations of data. \n",
    "* This is a **model-led approach** which has a strong mathematical underpinning and many powerful algorithmic tools which can be brought to bear.\n",
    "* This is **robust** (it appropriately represents uncertainty) and **generative** (it can simulate behaviour compatible with observations).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2eddf4f4d750c89334ec483a20beff3a977ef7807bc2815549a2bacb7799a306"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
