{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# set some styling defaults for matplotlib\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "mpl.rcParams[\"figure.dpi\"] = 90  # change this to set apparent figure size\n",
    "mpl.rcParams[\"figure.figsize\"] = (7, 3)\n",
    "mpl.rcParams[\"figure.frameon\"] = False\n",
    "\n",
    "# set decimal precision to 3 dec. places\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Theory and practice\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "You will understand:\n",
    "\n",
    "* What a Bayesian is.\n",
    "* The idea of a data generating process;\n",
    "* The relation of models and parameters;\n",
    "* What uncertainty is, where it comes from, and why it is important;\n",
    "* The evolution of probabilistic programming languages;\n",
    "* What probability is and how it represents uncertainty;\n",
    "* The distinction between prediction and inference and the relation to forward and inverse probability.\n",
    "* A high-speed review of basic probability theory through code: \n",
    "    * axioms of probability\n",
    "    * mass functions, distributions, random variables\n",
    "    * likelihood and sampling\n",
    "    * joint, marginal, conditional, Bayes' rule\n",
    "    * entropy, divergence\n",
    "* Major classes of inference algorithms\n",
    "\n",
    "## Poll\n",
    "\n",
    "## What is a Bayesian [I]?\n",
    "\n",
    "[FACETS_IMAGE]\n",
    "\n",
    "A Bayesian is someone who:\n",
    "\n",
    "* Is happy to live without truth;\n",
    "* Reasons from belief to belief, guided by evidence;\n",
    "* Thinks backwards by thinking forwards.\n",
    "\n",
    "### Without truth\n",
    "We might be used to computations that deal in absolute truths, but these aren't that useful for modelling. Very few processes are sufficiently stable and sufficiently well-understood that\n",
    "they can be precisely modelled without uncertainty. Only being capable of dealing in absolute truths is exceedingly limiting; it breeds fragility and irrationality. \n",
    "\n",
    "### Belief to belief\n",
    "A Bayesian computation does not result in a change of *state*, but a change of beliefs. This originates from some original beliefs and is then adjusted to be compatible with evidence that has been observed. This evidence typically concentrates belief on a tighter set of possible configurations. \n",
    "\n",
    "### Forwards, not back\n",
    "Bayesian modelling involves first mode;ling *what we might observe given a hypothesis* and not *what hypothesis to choose given an observation*. This is a very important distinction, and makes it trivial to combine evidence from multiple sources.\n",
    "\n",
    "\n",
    "## Models\n",
    "Let's get back to computational interaction. A tenet of the approach is that it puts models *first*. Every model in computational interaction will be a bit of code that is executed in order to gain insight into an interaction phenomena that we cannot directly access. Not all things that are called models are equivalent, however. We need to think about the characteristics that of models of interaction: are some better than others?\n",
    "\n",
    "### On the virtues of models\n",
    "Given two models that model some interaction phenomena equally well, we'd prefer the model that:\n",
    "\n",
    "* is easily implemented computationally and fit with software engineering practices;\n",
    "* is conveniently parameterised, with *interpretable* parameters;\n",
    "* is generative, and expressed in terms of generating synthetic observations;\n",
    "* is capable of propagating uncertainty correctly.\n",
    "\n",
    "\n",
    "## Data generating processes\n",
    " We need *models* to do *computational interaction*, and they need to be *executable*. We'd further like them to be *generative*. That implies code that simulates or emulates some part of an interactive system -- a **forward model** that transforms unknown states into the observable quantities they imply. At the heart of Bayesian modelling we have the idea of a **data generating process**, a process which we believe is generating data we observe. We implement this as an algorithm\n",
    "which generates synthetic observations. \n",
    "\n",
    "> This is just a function!\n",
    "\n",
    "\n",
    "Every application of Bayesian ideas starts with the data generating process: write down code that will spit out plausible simulations, given some configurable parameters.\n",
    "\n",
    "\n",
    "\n",
    "#### A very simple example\n",
    "Let's model how tall someone is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm_1():\n",
    "    return 180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That isn't a very inspiring model, but it is a computational model that we can execute. A better model would be parametric (i.e. takes parameters).\n",
    "\n",
    "### Parameters\n",
    "\n",
    "These are just the things that we can vary to change the result (i.e. parameters we pass in to the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm_2(gender):\n",
    "    if gender==\"male\":\n",
    "        return 175\n",
    "    if gender==\"female\":\n",
    "        return 162            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_2(\"male\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or multiple parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm_3(gender, age):\n",
    "    if gender == \"male\":\n",
    "        return 85 + min(age, 16) * 5.63\n",
    "    if gender==\"female\":\n",
    "        return 80 + min(age, 16) * 5.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_3(\"female\", 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Higher-level parameters\n",
    "\n",
    "We can have higher-level parameters, where the model includes parameters that determine other parameters. Sometimes we will have a mixture of *observed* values and *latent* (hidden) parameters; but this poses no problem in modelling. \n",
    "\n",
    "We often write things like $$y = f(x;\\theta)$$ to mean a function that produces simulated observations $y$, taking *observed* inputs $x$ and latent parameters $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Latent parameters\n",
    "### Now the \"magic constants\" are passed in as parameters\n",
    "def how_tall_cm_latent(gender, *, mean_height=160, m_f_difference=6.5):\n",
    "    if gender==\"male\":\n",
    "        return mean_height + m_f_difference\n",
    "    if gender==\"female\":\n",
    "        return mean_height - m_f_difference  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_latent(\"male\", m_f_difference=10.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Uncertainty\n",
    "\n",
    ">    All theorems are true.  \n",
    ">    All models are wrong.  \n",
    ">    And all data are inaccurate.  \n",
    ">    What are we to do?  \n",
    ">    We must be sure to remain uncertain. \n",
    "\n",
    "-- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* \n",
    "\n",
    "### What is uncertainty and where does it come from?\n",
    "Uncertainty exists in all systems that make contact with the real world. The physical world is not the domain of absolute logical truth, and the human social world is even less so. \n",
    "\n",
    "In interaction, we have, in the simplest case, two parties: \n",
    "\n",
    "* a brain, embedded in a human, embedded in a physical world\n",
    "* and software, embedded in computer hardware, embedded in the same physical world. \n",
    "\n",
    "[IMAGE]\n",
    "\n",
    "#### Epistemic, aleatoric and approximation\n",
    "\n",
    "We can separate out some *types* of uncertainty:\n",
    "\n",
    "* **Epistemic uncertainty** is uncertainty about what we know (hence epistemic) arising from the limitations of our knowledge (as encoded by a model). For example, we might model... [TODO]\n",
    "* **Aleatoric uncertainty** is that which arises from (presumed) randomness in the world. If I toss a coin, my uncertainty about which side lands face up is aleatoric. This type of uncertainty cannot be resolved by better modelling, more data, etc.; it is irreducible. [TODO]\n",
    "* **Approximation uncertainty** arises from the limitations of computation to approximate inference. In general, Bayesian methods cannot be applied exactly, and so the results are subject to additional uncertainty.\n",
    "\n",
    "#### The wonder-goop\n",
    "Uncertainty is what makes a model *statistical*, and it can be used to model real or apparent randomness in phenomena. But we often have to build simple, tractable models that we know are bad models of the real world -- they simply can't represent the true complexity of an interactive system. We can just add uncertainty as \"goop\" to soak up the variation between the truth and the model; we pretend that there is randomness to mask the misalignment. If done correctly, our inferences are still correct, and *represent* the degree to which they have misfit reality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(x):\n",
    "    return x + np.cos(x) * 0.2 - 0.0001 * x ** 4\n",
    "\n",
    "x = np.linspace(4, 16, 20)    \n",
    "y = f(x)\n",
    "p = np.polyfit(x, y, 1)\n",
    "y_prime = np.polyval(p, x)\n",
    "fig, ax = plt.subplots()\n",
    "err = 2\n",
    "for l in [0.25, 0.5, 1, 2]:\n",
    "    ax.fill_between(x, y_prime-l*err, y_prime+l*err, color='C0', alpha=0.2)\n",
    "\n",
    "ax.scatter(x, y, label='True', c='C1')\n",
    "ax.plot(x, y_prime, label='Approximate')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic results: sampling\n",
    "\n",
    "The simple models above are purely deterministic. In interaction, it's rare to have a model that can precisely predict an outcome, even if the parameters are known: models aren't exact representations of reality [epistemic], and reality isn't predictable anyway [aleatoric].\n",
    "\n",
    "A *statistical* data generating process would model the process with randomness, to reflect that we are drawing a (random) sample from a larger postulated population of possibilities. In practice, this just means we add random number generators to our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stochastic\n",
    "def how_tall_cm_4(gender):\n",
    "    if gender==\"male\":\n",
    "        return np.random.normal(175, 10)\n",
    "    if gender==\"female\":\n",
    "        return np.random.normal(162, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_4(\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_4(\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a a histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist([how_tall_cm_4(\"male\") for i in range(100)], label=\"Male\")\n",
    "ax.hist([how_tall_cm_4(\"female\") for i in range(100)], label=\"Female\")\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 220)\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic results: likelihood\n",
    "\n",
    "To do Bayesian modelling, we will need one more thing in our data generating processes: a measure of how \"likely\" an observation is to have been generated by the simulation. We can see this as a measure of compatibility of a possible observation with the particular parameters of a model.\n",
    "    \n",
    "> Note that we can sometimes work around this requirement, using **approximate Bayesian computation (ABC)** -- but this tends to be quite inefficient. Still, the ABC approach, means we can use any model, without this likelihood function. \n",
    "\n",
    "This special feature will be the key to letting us *invert* our simulator, and work out how it is configured by feeding it possible data it might have generated.\n",
    "\n",
    "For now, we'll assume we just get a number telling us how good a fit an observation is; the lower the number, the worse the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Likelihood: this is a function of data\n",
    "### There's no randomness here!\n",
    "def how_tall_cm_lik(gender, observed_height):    \n",
    "    if gender==\"male\":\n",
    "        return ss.norm(175, 10).logpdf(observed_height)\n",
    "    if gender==\"female\":\n",
    "        return ss.norm(162, 7).logpdf(observed_height)\n",
    "    \n",
    "print(\"male, 175cm tall\", how_tall_cm_lik(\"male\", 175))\n",
    "print(\"female, 175cm tall\", how_tall_cm_lik(\"female\", 175))\n",
    "print(\"male, 155cm tall\", how_tall_cm_lik(\"male\", 155))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"male 17.5cm tall\", how_tall_cm_lik(\"male\", 17.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a plot of likelihood \n",
    "fig, ax = plt.subplots()\n",
    "heights = np.linspace(0, 350, 350)\n",
    "ax.plot(heights, [how_tall_cm_lik(\"male\", h) for h in heights], label=\"Male\")\n",
    "ax.plot(heights, [how_tall_cm_lik(\"female\", h) for h in heights], label=\"Female\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"Log-likelihood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a a histogram\n",
    "fig, ax = plt.subplots()\n",
    "for mean_height in [150, 160, 170, 180]:\n",
    "    ax.hist([how_tall_cm_5(\"male\", mean_height=mean_height) for i in range(100)], label=f\"mean={mean_height}cm\", alpha=0.7)\n",
    "    \n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlim(0, 220)\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion\n",
    "\n",
    "### A mysterious entity\n",
    "\n",
    "<img src=\"imgs/entity.png\">\n",
    "\n",
    "The data generating process as a tame mysterious entity, who generates samples when simulating and can judge the quality of observations when fed them.  The mysterious entity is controlled by parameters (dials) which adjust the simulation and its opinion of the quality of observations. What we want is to know *which* mysterious entities are compatible with the true (but unseen) mysterious entity.\n",
    "\n",
    "### Bayesian inversion\n",
    "\n",
    "This is a problem of **inversion**; working out what was happening in the unobserved realm by deducing plausible behaviours compatible with the observations. Working out what age someone is given how tall they are is an inverse problem. Working out how tall they are given their age is a forward problem. In Bayesian modelling we use the **forward** model (the data generating process) as the key step to build our inversion model. \n",
    "\n",
    "[TODOINVERSIONIMAGE]\n",
    "\n",
    "> Other approaches solve inversion directly; for example we might build a machine learning model that predicts ages given heights by fitting a deep network to lots of paired `(age, height)` examples. We could then, at inference time, feed it a height and it would return an age. Critically, it would only return *one* age -- the best predicted age (as directed by the objective function used to train the network). This is very much **not** what we will do in the Bayesian models we will see later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Computer science: inversion the advance of [scientific] programming languages\n",
    "\n",
    "Advances in programming languages change the way we express models, and implicitly how we think about modelling the world. \n",
    "\n",
    "#### Traditional: Python, C, Java, Rust, C#, ...\n",
    "We express models as operations on primitives, like numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x ** 2 + x - 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorised: NumPy, eigen, Julia, ...\n",
    "We express models directly over numerical arrays (\"tensors\"). Code gets shorter, cleaner, and more efficient, takes advantage of hardware, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f(x):\n",
    "    return np.sum(x**2 + x - 2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable: autograd, JAX, PyTorch, TensorFlow, ...\n",
    "Defining a function over numerical arrays *automatically* also defines a function returning the partial derivatives. Universal first-order optimisation (gradient descent) becomes available.\n",
    "\n",
    "* *Now we can write **inverse programs**: we define the output, and solve for the input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as anp\n",
    "import autograd\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return anp.sum((x**2 + x - 2) ** 2, axis=1)\n",
    "\n",
    "\n",
    "df = autograd.elementwise_grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = anp.eye(4)\n",
    "print(f(x))\n",
    "print(df(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if only we had some way of repeating\n",
    "# things on a computer\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Probabilistic (PPLs): Stan, PyMC, Turing.jl, BUGS/JAGS, ...\n",
    "This adds distributions to programs. It automatically includes *random simulation*, *likelihood* and most importantly *inference*.\n",
    "\n",
    "We don't need a PPL to do random simulation (a **stochastic model**):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward: random simulation\n",
    "def f(x):\n",
    "    x = np.array(x)\n",
    "    y = np.random.normal(0, 1, x.shape)\n",
    "    return x**2 + x - 2 + y\n",
    "\n",
    "\n",
    "# different on every run\n",
    "# models variation in the world\n",
    "f([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or to do the inverse; compute the likelihood of (stochastic) observations under a parameterised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llik_f(x, y):\n",
    "    x = np.array(x)\n",
    "    # return log-lik of observations y under model settings x\n",
    "    return np.sum(ss.norm(x**2 + x - 2, 1).logpdf(y))\n",
    "\n",
    "\n",
    "print(llik_f([1, 2, 3], f([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but to do the **inference** part -- to work out the relative probability of possible inputs that might have generated an observation -- we'd be much better off using a real probabilistic programming language. This will implement efficient algorithm to allow us to write **uncertain inverse programs**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## What is a Bayesian [II]?\n",
    "\n",
    "A Bayesian:\n",
    "\n",
    "* Represents, preserves and manipulates uncertainty about unknown states. Uncertainty is **first-class**.\n",
    "* Builds generative models of the phenomena under consideration, that simulate plausible observations.\n",
    "* Reasons about the unknown parameters that modulate the behaviour of those generative models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "We need to formalise the representation of uncertainty in our models. There are many possible ways to do this, but arguably only one good way: **probability**. Bayesians represent all uncertainty via probability, and describe the relative plausibility of states via **probability distributions**.\n",
    "\n",
    "### What is probability?\n",
    "\n",
    "A fraught philosophical question! See the references for debates on this topic. We'll make some uncontroversial statements, then an *interpretation* of probability.\n",
    "\n",
    "**Probability, as we shall use it, is simply an extension of ordinary logic to uncertain situations.**\n",
    "\n",
    "\n",
    "#### Basic facts\n",
    "\n",
    "\n",
    "\n",
    "* A probability distribution associates a set of distinct *outcomes* to probabilities. $P(X=x)$ meaning the probability that variable $X$ takes on outcome $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(outcomes, ps):\n",
    "    return {out:p for out, p in zip(outcomes, ps)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probabilities are non-negative and cannot exceed 1: $0 \\leq P(A) \\leq 1$ \n",
    "* The probability of all possible outcomes in a distribution sums to 1 exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper(dist):\n",
    "    ps = dist.values()\n",
    "    assert all(0<=p<=1 for p in ps), \"Probability is not in [0,1]\"\n",
    "    assert sum(ps) == 1.0, \"Distribution does not sum to 1\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We deal with sets of possible outcomes; the set of all outcomes in our \"model\" is the *sample space*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_space(dist):\n",
    "    return list(dist.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An *event* is any set of outcomes. \n",
    "* => If A and B are events $P(A \\lor B) = P(A) + P(B) - P(A\\land B)$ (sum rule; A and B are sets of outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_of(event, dist):\n",
    "    return sum(p for outcome, p in dist.items() if outcome in event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rule(a, b, dist):\n",
    "    p_a = p_of(a, dist)\n",
    "    p_b = p_of(b, dist)\n",
    "    p_ab = p_of(a.intersect(b), dist)\n",
    "    return p_a + p_b - p_ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of any set of disjoint events that cover all outcomes is therefore also 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* => If A has probability $P(A)=P(X \\in A)$, $P(¬A)=P(X \\notin A)=1-P(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of two *independent* events A and B is $P(A \\land B) = P(A)P(B)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_rule(a, b, dist_a, dist_b):\n",
    "    return p_of(a, dist_a) * p_of(b, dist_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of A *given we know that* an event B is true is written $P(A|B) = P(A \\land B)/P(B)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional(a, b, dist_ab):\n",
    "    p = 0\n",
    "    for o_a, o_b in dist_ab.items():\n",
    "        if o_b == b:\n",
    "            p += o_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of P(A|B) is **not** in general P(B|A).\n",
    "* $P(A|B) = P(B|A)P(A) / P(B)$ (Bayes' Rule)\n",
    "* $P(B) = \\sum_B P(B|A)P(A)$ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I grab a single coin from my pocket. We assume they are all Euros. That's our space of possibilities.\n",
    "\n",
    "* The probability of the coin being worth >50c is an *event*; perhaps $P(v>0.5)=P(v \\in {1.0, 2.0})=0.33$\n",
    "* Regardless of what distribution of coins I have in my pocket, it cannot be less than impossible to pick a specific coin, nor more than certain.\n",
    "* A probability distribution might map each coin (outcome) to a probability, a real number in [0,1]; for example:\n",
    "    * [REPLACEWITHIMAGE]\n",
    "    * P(v=0.01) = 0.02\n",
    "    * P(v=0.02) = 0.05\n",
    "    * P(v=0.05) = 0.1\n",
    "    * P(v=0.10) = 0.1\n",
    "    * P(v=0.20) = 0.2\n",
    "    * P(v=0.50) = 0.2\n",
    "    * P(v=1.00) = 0.3\n",
    "    * P(v=2.00) = 0.03\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = {0.01: 0.02,\n",
    "         0.02 : 0.05,\n",
    "         0.05 : 0.1,\n",
    "         0.1 : 0.1,\n",
    "         0.2 : 0.2, \n",
    "         0.5 : 0.2,\n",
    "         1.0 : 0.3,\n",
    "         2.0 : 0.03}\n",
    "\n",
    "proper(coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A coin might be worth less than 10 cents $P(v<0.1) = P(v \\in \\{0.01, 0.02, 0.05\\})$ or being gold-coloured $P(v \\in \\{0.1, 0.2, 0.5\\})$, or being 1 euro $P(v \\in \\{1.0\\})$. These are all events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_coins = sample_space(coins)\n",
    "gold = [0.1, 0.2, 0.5]\n",
    "\n",
    "print(p_of([coin for coin in possible_coins if coin<0.1], coins))\n",
    "print(p_of(gold, coins))\n",
    "print(p_of([1.0], coins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since we must draw exactly one coin, the event that includes all coins must have probability 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_of(possible_coins, coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of a coin being less than 20c or more than *or* equal to 20c must also be 1.0, by the same logic (we cover every outcome exactly once). $P(v < 0.2 \\lor v\\geq 0.2) = P(v<0.2) + P(v \\geq 0.2) = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.1\n",
    "(p_of([coin for coin in possible_coins if coin<k], coins) + p_of([coin for coin in possible_coins if coin>=k], coins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of a coin being not gold coloured in one minus the probability of being gold coloured $P(gold) + P(¬gold) = 1$, $P(¬gold) = 1 - P(gold)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_gold = set(coins) - set(gold)\n",
    "p_of(gold, coins) + p_of(not_gold, coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of a coin being less than 50c or being gold-coloured is $P(v < 0.5 \\lor v \\in \\{0.2, 0.5\\}) = P(v<0.5) + P(v \\in \\{0.2, 0.5\\}) - P(v<0.5 \\land v \\in \\{0.2, 0.5\\}) = P(v<0.5) + P(v \\in \\{0.2, 0.5\\}) - P(v=0.5)$ -- we compensate for \"double counting\" the overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gold_or_50 = (p_of(gold, coins) \n",
    "                + p_of([coin for coin in coins if coin<0.5], coins) \n",
    "                - p_of([coin for coin in coins if coin<0.5 and coin in gold], coins))\n",
    "\n",
    "print(p_gold_or_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_or_50 = set(gold) | set([coin for coin in coins if coin<0.5])\n",
    "print(p_of(gold_or_50, coins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability that I draw a coin that is gold coloured and it is a Spanish coin is $P(gold \\land Spanish) = P(gold)P(Spanish)$, assuming these are independent (e.g. I don't specially collect gold-coloured Spanish euro coins)\n",
    "    * But the probability that I draw coin that is copper coloured and Finnish is **not** $P(copper)P(Finnish)$ (because 1c and 2c Finnish coins are very rare)\n",
    "* The probability that I draw a gold coin given that the coin is less than a euro is $P(gold | v<1.0) = P(v \\in \\{0.1, 0.2, 0.5\\}) / P(v \\in \\{0.01, 0.02, 0.05, 0.1, 0.2, 0.5\\}) \\approx 0.746...$\n",
    "* The probability that I draw a coin less than a euro given that it is gold is $P(v < 1.0 | gold) = P(v \\in \\{0.1, 0.2, 0.5\\}) / P(v \\in \\{0.1, 0.2, 0.5\\}) = 1.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Random variables and distributions\n",
    "\n",
    "* A **random variable** $X$ is a variable whose value is not known, but whose possible values *are* known, and how likely those values are is also known. Probability theory allows us to manipulate random variables without having to assign them a specific value.\n",
    "* A **probability distribution** $P(X=x)$ associates a random variables outcomes to probabilities. It encodes the plausibility of a variable's outcomes.\n",
    "* A **probability mass function** $f_X(x)$ is a function that yields probabilities as a function of outcomes.\n",
    "* If we have uncountable outcomes (like real numbers), we instead use a **probability density function** $f_X(x)$, which just guarantees the rules above hold for dense subsets of the outcomes, even if they can't hold for individual outcomes.\n",
    "    * Densities are not probabilities! They are non-negative, but can be greater than 1; the *integral* of a density over some domain *is* a probability. (e.g. $P(1\\leq age \\leq 2) = \\int_1^2 f_X(age) dx$ over the interval [1, 2] of $\\mathbb{R}$) \n",
    "\n",
    "A random variable could represent:\n",
    "\n",
    "\n",
    "[IMAGEHERE]\n",
    "* whether or not a user is paying attention (discrete: binary), over the set of outcomes $\\{\\text{attending}, \\text{ignoring}\\}$; \n",
    "* the page of a document a user is reading $\\{1,2,3,\\dots\\}$ (discrete); \n",
    "* the length of a user's arm (continuous), over the set of outcomes $\\real$; \n",
    "* the gaze angle of a user's pupil with respect to a screen (continuous, multi-dimensional), over the set of outcomes $\\real^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "A **probability distribution** defines how likely different states of a random variable are. \n",
    "\n",
    "We can see $X$ as the the *experiment* and $x$ as the *outcome*, with a function mapping every possible outcome to a probability. \n",
    "\n",
    "> Be careful: these are *notional* experiments, not real ones. They might involve things that are in the past, or have no randomness. They are subjective experiments from the perspective of an agent. \n",
    "\n",
    "$$\n",
    "P(A),\\  \\text{the probability of an event A}, \\text{equivalent to} P(X \\in A)\\\\\n",
    "P(X=x),\\  \\text{the probability of random variable X taking on value x}\\\\\n",
    "P(X),\\  \\text{shorthand for distribution of X }\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful!\n",
    "\n",
    "p_of({1, 2}, {1:0.5, 2:0.2, 3:0.1, 4:0.1}) # P(A), a number (from a set of outcomes)\n",
    "p_of({1}, {1:0.5, 2:0.2, 3:0.1, 4:0.1})    # P(X=x), a number from an outcome\n",
    "{1:0.5, 2:0.2, 3:0.1, 4:0.1}               # P(X), a distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Philosophy\n",
    "\n",
    "We will use the subjective Bayesian interpretation of probability. This has a simple statement but deep implications.\n",
    "\n",
    "* Probability is a *degree of belief*.\n",
    "* We express how strongly we believe something to be true with a probability. \n",
    "* We encode all beliefs as probability distributions. It's probabilities all the way down.\n",
    "* We manipulate all beliefs via the rules above. This naturally includes all of classical logic, where P=0 is False and P=1 is True.\n",
    "* We might expect that these probabilities would be *consistent* with observed relative frequencies of some random repeated process, but **that's not our definition of probability**. We do not invoke the mystical infinitely repeated identical experiments!\n",
    "* It's completely fine to make statements like \"the probability that it is raining right now\", \"the probability that 2^10^10^10-1 is prime\" or \"the probability that the 2012 Olympics was in London\" (think carefully about what the probability might be!)\n",
    "* Because this form of probability theory is merely a logic of uncertain beliefs, we must always reason from some starting point. Rather than **axioms**, as in classical logic, we instead begin from **priors**, associating beliefs to probabilities at the start of a reasoning process.\n",
    "\n",
    "> We shall move from \"what proportion of times will I draw a 50c coin from my pocket?\" to \"what do you *believe* about my having a 50c coin?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random parameters\n",
    "* We will associate probability distributions with the *parameters* of our data generating processes!\n",
    "    * After all, we want to encode beliefs about what parameters could be reasonable.\n",
    "* These distributions capture our *epistemic* uncertainty; they in turn may drive generation of random observations which have *aleatoric* uncertainty.\n",
    "* This means that we will have distributions over processes, who in turn (usually) have distributions over possible observations.\n",
    "* When we talk about Bayesian inference, we are talking about updating probability distributions over these parameters, given definite observations.\n",
    "\n",
    "## Computer science\n",
    "\n",
    "* Probability is a **universal language** for expressing uncertain states.\n",
    "* Anything that \"speaks probability\" can be plugged into any other component that also does so.\n",
    "    * (at least if we can map sample spaces onto each other)\n",
    "* Probability is easy to encode in data structures for finite, discrete problems and the algorithms are simple\n",
    "    * A hash table/dictionary or plain array can do most of the work\n",
    "* It is harder in continuous, multi-dimensional spaces or those with exotic topology.\n",
    "    * Consequently, we will virtually always have to **approximate** probabilities in these situations.\n",
    "    * And we will have to build and use approximation algorithms to do the hard work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability mass functions and probability density functions\n",
    "\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a CDF plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def how_tall_cm_pdf(gender, observed_height):    \n",
    "    if gender==\"male\":\n",
    "        return ss.norm(175, 10).pdf(observed_height)\n",
    "    if gender==\"female\":\n",
    "        return ss.norm(162, 7).pdf(observed_height)\n",
    "    \n",
    "heights = np.linspace(0, 350, 350)\n",
    "ax.plot(heights, [how_tall_cm_pdf(\"male\", h) for h in heights], label=\"Male\")\n",
    "ax.plot(heights, [how_tall_cm_pdf(\"female\", h) for h in heights], label=\"Female\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"$f_X$(height)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a CDF plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def how_tall_cm_cdf(gender, observed_height):    \n",
    "    if gender==\"male\":\n",
    "        return ss.norm(175, 10).cdf(observed_height)\n",
    "    if gender==\"female\":\n",
    "        return ss.norm(162, 7).cdf(observed_height)\n",
    "    \n",
    "heights = np.linspace(0, 350, 350)\n",
    "ax.plot(heights, [how_tall_cm_cdf(\"male\", h) for h in heights], label=\"Male\")\n",
    "ax.plot(heights, [how_tall_cm_cdf(\"female\", h) for h in heights], label=\"Female\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"P(X<height)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We seek a logical process to perform inference: the deduction of the hidden from the seen. We seek to do so under uncertainty, where we do not deal in absolutes of truth and falsity.\n",
    "\n",
    "* Our primary tool is Bayes Rule. \n",
    "* The ability to do inference is derived from the ability to say: how likely is some unseen X given we saw Y?\n",
    "    * \"How likely is it that a coin is more than five years old given it is heavily corroded?\"\n",
    "        * I can see corrosion; I can't see age.\n",
    "    * We can answer that as:\n",
    "        * It is the probability that we'd observe Y if X were true; multiplied by how likely we *already* believe X to be true; and normalised so that the probability for each possible X sums up to 1.\n",
    "        * $P(X|Y) = P(Y|X)P(X) / P(Y) = P(Y|X)P(X) / \\sum_X P(Y|X)P(X)$\n",
    "        * $P(X|Y) \\propto P(Y|X)P(X)$ if all we care about is how *relatively* likely each possible $X$ is (not how *absolutely* likely it is)\n",
    "    * These parts have names:\n",
    "        * `posterior = likelihood * prior / evidence`\n",
    "        * **posterior** The probability of beliefs about $X$ after having observed $Y$\n",
    "        * **likelihood** How likely $Y$ is to be observed under any possible hypothesised $X$\n",
    "        * **prior** How currently likely $X$ is before observing $Y$\n",
    "        * **evidence** How likely $Y$ is to be observed regardless of what hypothesis we make about $X$\n",
    "\n",
    "* The likelihood of X, written $L(X)$ is how likely $X$ is to be observed under a particular model. Often written $L(X|\\theta)$ to mean \"the likelihood of X under some specific parameters \\theta\".\n",
    "    * Probabilities speak of the \"future\", of the relative propensity for unobserved outcomes to occur.\n",
    "    * Likelihoods speak of the \"past\", of observed states. They are just a function of observations/data, and they tell us how likely observed outcomes are under some assumption.\n",
    "    * The likelihood is $L(x) = f_X(x)$, just the mass/density evaluated for a specific outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and inverse probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Bayesian? [III]\n",
    "\n",
    "A **Bayesian**:\n",
    "\n",
    "* Represents belief exclusively using probability distributions and conducts all computation about beliefs via the logic of probability.\n",
    "* Reasons from hypotheses about the world to the evidence that those hypotheses would generate (via a data generating process).\n",
    "* Updates belief using Bayes' Rule, combining a prior belief with observed evidence to deduce new beliefs.\n",
    "* Infers conditional distributions -- posterior distributions -- over unseen parameters of the DGP.\n",
    "\n",
    "Given a parameterised simulator that approximates the problem we are interested in, and some idea about what values these parameters could take on (expressed as a prior probability distribution) we can then use evidence to make a Bayesian update to concentrate a belief distribution on more likely parameter configurations --- a posterior probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(outcome, pmf):\n",
    "    return pmf[outcome]\n",
    "\n",
    "def loglik(outcomes, pmf):\n",
    "    return sum(np.log(outcome) for outcome in outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(pmf, n=1):\n",
    "    return np.random.choice(list(pmf.keys()), p=list(pmf.values), size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def from_empirical(observations):\n",
    "    c = Counter(observations)\n",
    "    total = sum(c.values())\n",
    "    return {outcome: count / total for outcome, count in c.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect(pmf, g=lambda x: x):\n",
    "    return sum(g(outcome) * p for outcome, p in pmf.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate expectation\n",
    "\n",
    "$$ E[g(X)] \\approx \\frac{1}{N} \\sum_{i=1}^{N} g(x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_approx(sample_fn, n, g=lambda x: x):\n",
    "    return sum(g(sample_fn()) for i in range(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(pmf):\n",
    "    return -sum(p * np.log2(p) for p in pmf.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes(pmf, likelihood):\n",
    "    unnorm = {k: pmf[k] * likelihood[k] for k in pmf}\n",
    "    s = sum(unnorm.values())\n",
    "    return PMF({unnorm[k] / s for k in unnorm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bayes_table(pmf, likelihood):\n",
    "    unnorm = {k: pmf[k] * likelihood[k] for k in pmf}\n",
    "    s = sum(unnorm.values())  \n",
    "    posterior =  {k:unnorm[k] / s for k in unnorm}\n",
    "    df = pd.DataFrame(zip(pmf.values(), likelihood.values(), unnorm.values(), posterior.values()), columns = [\"Prior\", \"Likelihood\", \"Unnormalised\", \"Posterior\"])\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = {1:0.5, 2:0.5}\n",
    "likelihood = from_empirical([1,2,2])\n",
    "bayes_table(prior, likelihood)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint(self, other):\n",
    "    \"\"\"Only valid for two *independent* PMFs!\"\"\"\n",
    "    return (\n",
    "        {\n",
    "            (a, b): p_a * p_b\n",
    "            for (a, p_a), (b, p_b) in itertools.product(\n",
    "                pmf.items(), pmf.items()\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "joint({1: 0.2, 2: 0.8}, {\"cat\": 0.1, \"dog\": 0.9})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal(pmf, mask):\n",
    "    acc = {}\n",
    "    for outcome, p in pmf.items():\n",
    "        removed = tuple([component for elt, component in zip(mask, outcome) if mask])        \n",
    "        acc[removed] = acc.get(removed, 0) + p\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditional\n",
    "def conditional(self, n):\n",
    "    p_B = self.marginal(n)\n",
    "\n",
    "    for outcome, p in self.pmf.items():\n",
    "        p / p_B.pmf[outcome[n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Let's look a simple example: capturing and reporting user ratings for a component.\n",
    "\n",
    "> 86% of users liked this.\n",
    "\n",
    "### Assumptions\n",
    "We have a UI that shows how many people liked or disliked a product. Individual users provide ratings by clicking either 👍 or 👎. \n",
    "\n",
    "We assume a population of users, and we want to know how \"good\" that population (as a single entity) thinks that product is; the \"hive mind\". \n",
    "\n",
    "### Data generating process\n",
    "* Step 1: describe the data generating process.\n",
    "\n",
    "We'll assume this simple model: the hive mind has a value $q$ between 0 and 1 that it ascribes to every product. Individual users, as drones of the hive mind, randomly produce likes or dislikes *in proportion* to this value. \n",
    "\n",
    "#### Observations\n",
    "A variable length sequence of 👍 or 👎.\n",
    "\n",
    "#### Code\n",
    "* Step 2: write down the simulator that generates samples, and a likelihood function that tells us how likely they are.\n",
    "\n",
    "We can now define a simulator in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q -> epistemic uncertainty\n",
    "# we assume that n is independent \n",
    "# (but we don't have to)\n",
    "def product_sample(q, n):\n",
    "    # likes -> aleatoric uncertainty\n",
    "    likes = np.random.choice([\"👍\",\"👎\"], size=n, p=[q, 1-q])\n",
    "    return \"\".join(likes)\n",
    "\n",
    "product_sample(0.25, 10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a likelihood function. In this case, it's easy: we have probability `q` of seeing a \"👍\" and a probability of `1-q` of seeing a 👍. We can return the sum of log-likelihoods for a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lik(o):\n",
    "        return q if o=='👍' else 1-q\n",
    "    \n",
    "# return the log-likelihood of a string \n",
    "# under some specific setting of q    \n",
    "def product_llik(q, obs):    \n",
    "    return sum(np.log(lik(o)) for o in obs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian estimation\n",
    "* Step 3: collect, process and clean data (omitted for clarity!)\n",
    "* Step 4: perform inference\n",
    "\n",
    "What is inference in this case? We want to perform deduction -- invert the simulator so that we can work out `q` by observing sequences of characters. \n",
    "\n",
    "**We are Bayesian.** Therefore, we don't want a value for `q`, we want a *distribution* for `q`. \n",
    "\n",
    "> Distributions, not points!\n",
    "\n",
    "This implies:\n",
    "* We need to have a way of representing a distribution over `q` -- what data structure will we choose? (and what algorithm will that require?)\n",
    "* We need to start somewhere -- what prior for `q` will we believe *before we observe any product like data*?\n",
    "\n",
    "We'll use the simple grid model as our data structure, and evenly divide the interval [0, 1] into N discrete bins. I'll choose to set N=20 (but this is a fairly arbitrary choice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting results\n",
    "\n",
    "### Expectation\n",
    "\n",
    "### Probabilistic filtering and sequential (\"recursive\") updates\n",
    "\n",
    "The names *prior* and *posterior* can refer to distinct parts of a modelling process (e.g. I elicit a prior from an expert, then run an experiment to observe data that I use to compute a posterior). But the naming of prior and posterior is *purely relative*! \n",
    "\n",
    "It's completely fine for a prior for one step of an inference process to become the posterior for another step. Everything is just probability distributions, which are a universal language -- everything plugs together (over the same sample space, anyway).\n",
    "\n",
    "![Recursive updates](imgs/recursive.png)\n",
    "\n",
    "\n",
    "### Sensor fusion\n",
    "\n",
    "### Bayesian optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow worlds\n",
    "\n",
    "[SHADOW_WORLD_IMAGE]\n",
    "\n",
    "### (Prior, posterior) x (parameter, predictive)\n",
    "\n",
    "It's important to keep the various elements of a Bayesian model distinct.\n",
    "\n",
    "#### Over parameters (inference)\n",
    "* **Prior** a distribution over unknown parameters before some observations\n",
    "* **Posterior** a distribution over unknown parameters after observations\n",
    "\n",
    "#### Over observations (simulation)\n",
    "* **Prior predictive** a distribution over observations *that our model would generate* under the priors.\n",
    "* **Posterior predictive** a distribution over observations *that our model would generate* under the posterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Inference approaches\n",
    "\n",
    "### The process of eliciting, encoding and validating\n",
    "What does it look like to *do* Bayesian modelling? We need to do several things:\n",
    "\n",
    "* Elicit models (data generating processes) that we believe are good fits to the phenomena;\n",
    "* Encode our beliefs about plausible configurations of those models mathematically, as prior distributions on parameters.\n",
    "* Infer posterior distributions over those parameters using an inference algorithm.\n",
    "* Validate that our modelling assumptions held true.\n",
    "\n",
    "#### Elicit and encode\n",
    "\n",
    "#### Validate\n",
    "\n",
    "\n",
    "### Concrete algorithms for inference\n",
    "In general, we wouldn't use the grid type models we have seen for real problems.\n",
    "\n",
    "* **Q: Why not?**\n",
    "\n",
    "Practical algorithms for problems that involve continuous variables fall into three basic types. We'll see each type applied to a very simple problem. \n",
    "\n",
    "#### Exact\n",
    "Very occasionally, we can compute the exact density function for a posterior distribution by some algebraic trickery. This is only possible if our prior and likelihood have a very specific form. \n",
    "\n",
    "##### Data structure\n",
    "* Parameter vectors (associated with density functions)\n",
    "\n",
    "##### Algorithm\n",
    "\n",
    "Direct computation.\n",
    "\n",
    "* We have a **parametric** form for our prior density $f(\\theta)$ (e.g. a normal distribution with parameters $\\mu$ and $\\sigma^2$).\n",
    "* We have a collection of observations\n",
    "* We have a **parametric** likelihood that is compatible with our prior density function; $L(x|\\phi)$\n",
    "* We run an algorithm that computes a **parametric** density function for the posterior $g(\\psi)$.\n",
    "\n",
    "$f$, $L$ and $g$ don't have to have the same form (e.g. they might not all be normal), but they do have to be compatible (\"conjugate priors\"). \n",
    "\n",
    "\n",
    "#### Pros and cons\n",
    "\n",
    "* Advantages: Extremely efficient; no approximation error.\n",
    "* Disadvantages: constrains you to a small range of modelling choices; requires special implementation for each case; can be complicated to understand.\n",
    "\n",
    "#### MCMC\n",
    "\n",
    "##### Data structure\n",
    "* Samples (i.e. sequences of values in the sample space *of parameters*)\n",
    "\n",
    "##### Algorithm\n",
    "\n",
    "Stochastic process.\n",
    "\n",
    "#### Pros and cons\n",
    "* Advantages: extremely general (\"one button inference\"); samples are easy to work with (just arrays of definite numbers); lots of sophisticated algorithms\n",
    "* Disadvantages: may not converge; lots of tuning and tweaking to get sampling to work; some problems are very resistant to sampling based solutions (e.g. exotic geometry, partially discrete problems)\n",
    "\n",
    "#### Variational\n",
    "\n",
    "##### Data structure\n",
    "* Samples (i.e. sequences of values in the sample space *of parameters*)\n",
    "\n",
    "##### Algorithm\n",
    "\n",
    "Optimisation.\n",
    "\n",
    "## What is a Bayesian [IV]\n",
    "\n",
    "* Applies algorithms such as MCMC or variational inference to infer probability distributions over hidden states from observed data.\n",
    "* Implements data generating processes as computational simulators of expected phenomena, and can simulate concrete implications of hypotheses.\n",
    "* Reports and summarises inferences via approximations that are computationally tractable (e.g. via random samples)\n",
    "* Is typically concerned with *expectations* of a score function applied to a distribution, such as utility.\n",
    "* Freely fuses evidence from any source, in the past, present or future.\n",
    "\n",
    "\n",
    "\n",
    "### Why is this Computational HCI?\n",
    "\n",
    "* We build **statistical models** of user behaviour, and estimate parameters of that model from quantitative observations of data. \n",
    "* This is a **model-led approach** which has a strong mathematical underpinning and many powerful algorithms which can be brought to bear.\n",
    "* This is **robust** (it appropriately represents uncertainty) and **generative** (it can simulate behaviour compatible with observations).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2eddf4f4d750c89334ec483a20beff3a977ef7807bc2815549a2bacb7799a306"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
