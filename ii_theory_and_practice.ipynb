{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Theory and practice\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "You will understand:\n",
    "\n",
    "* What a Bayesian is.\n",
    "* The idea of a data generating process;\n",
    "* The relation of models and parameters;\n",
    "* What uncertainty is, where it comes from, and why it is important;\n",
    "* The evolution of probabilistic programming languages;\n",
    "* What probability is and how it represents uncertainty;\n",
    "* The distinction between prediction and inference and the relation to forward and inverse probability.\n",
    "* A high-speed review of basic probability theory through code: \n",
    "    * axioms of probability\n",
    "    * mass functions, distributions, random variables\n",
    "    * likelihood and sampling\n",
    "    * joint, marginal, conditional, Bayes' rule\n",
    "    * entropy, divergence\n",
    "* Major classes of inference algorithms\n",
    "\n",
    "## Poll\n",
    "\n",
    "## What is a Bayesian [I]?\n",
    "\n",
    "[FACETS_IMAGE]\n",
    "\n",
    "A Bayesian is someone who:\n",
    "\n",
    "* Is happy to live without truth;\n",
    "* Reasons from belief to belief, guided by evidence;\n",
    "* Thinks backwards by thinking forwards.\n",
    "\n",
    "### Without truth\n",
    "We might be used to computations that deal in absolute truths, but these aren't that useful for modelling. Very few processes are sufficiently stable and sufficiently well-understood that\n",
    "they can be precisely modelled without uncertainty. Only being able to deal in absolute truths is exceedingly limiting; it breeds fragility and irrationality. \n",
    "\n",
    "### Belief to belief\n",
    "\n",
    "\n",
    "\n",
    "### Forwards, not back\n",
    "\n",
    "\n",
    "## Models: Data generating processes\n",
    "Let's get back to computational interaction. We need *models* to do computational interaction, and they need to be *executable*. That means code that simulates or emulates some interaction\n",
    "element of interest. At the heart of Bayesian modelling we have the idea of a **data generating process**, a process which we believe is generating data we observe. We implement this as an algorithm\n",
    "which generates synthetic observations. This is just a function.\n",
    "\n",
    "Let's model how tall someone is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm():\n",
    "    return 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That isn't a very inspiring model, but it is a computational model that we can execute. A better model would be parametric (i.e. takes parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm(gender):\n",
    "    if gender==\"male\":\n",
    "        return 180\n",
    "    if gender==\"female\":\n",
    "        return 160            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or multiple parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm(gender, age):\n",
    "    if gender == \"male\":\n",
    "        return ###\n",
    "    if gender==\"female\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stochastic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or higher-level parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[Image]\n",
    "\n",
    "\n",
    "\n",
    "### Computer science: the advance of [scientific] programming languages\n",
    "\n",
    "Advances in programming languages change the way we express models, and implicitly how we think about modelling the world. A model can be written as a *function*.\n",
    "\n",
    "#### Traditional: Python, C, Java, Rust, C#, ...\n",
    "We express models as operations on primitives, like numbers.\n",
    "\n",
    "```python\n",
    "def f(x):\n",
    "    return x ** 2 + x - 2 \n",
    "```\n",
    "\n",
    "#### Vectorised: NumPy, eigen, Julia, ...\n",
    "We express models directly over numerical arrays (\"tensors\"). Code gets shorter, cleaner, and more efficient, takes advantage of hardware, etc.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "def f(x):\n",
    "    return np.sum(x**2 + x - 2, axis=1)\n",
    "```\n",
    "\n",
    "### Differentiable: autograd, JAX, PyTorch, TensorFlow, ...\n",
    "Defining a function over numerical arrays *automatically* also defines a function returning the partial derivatives. Universal first-order optimisation (gradient descent) becomes available.\n",
    "\n",
    "* *Now we can write **inverse programs**: we define the output, and solve for the input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as anp\n",
    "import autograd\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return anp.sum((x**2 + x - 2) ** 2, axis=1)\n",
    "\n",
    "\n",
    "df = autograd.elementwise_grad(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = anp.eye(4)\n",
    "print(f(x))\n",
    "print(df(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if only we had some way of repeating\n",
    "# things on a computer\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))\n",
    "x = x - df(x) * 0.1\n",
    "print(f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Probabilistic (PPLs): Stan, PyMC, Turing.jl, BUGS/JAGS, ...\n",
    "This adds distributions to programs. It automatically includes *random simulation*, *likelihood* and most importantly *inference*.\n",
    "\n",
    "We don't need a PPL to do random simulation (a **stochastic model**):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# forward: random simulation\n",
    "def f(x):\n",
    "    x = np.array(x)\n",
    "    y = np.random.normal(0, 1, x.shape)\n",
    "    return x**2 + x - 2 + y\n",
    "\n",
    "\n",
    "# different on every run\n",
    "# models variation in the world\n",
    "f([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or to do the inverse; compute the likelihood of (stochastic) observations under a parameterised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llik_f(x, y):\n",
    "    x = np.array(x)\n",
    "    # return log-lik of observations y under model settings x\n",
    "    return np.sum(ss.norm(x**2 + x - 2, 1).logpdf(y))\n",
    "\n",
    "\n",
    "print(llik_f([1, 2, 3], f([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but to do the **inference** part -- to work out the relative probability of possible inputs that might have generated an observation -- we'd be much better off using a real probabilistic programming language. This will implement efficient algorithm to allow us to write **uncertain inverse programs**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parameters and models\n",
    "\n",
    "## Uncertainty\n",
    "\n",
    ">    All theorems are true.  \n",
    ">    All models are wrong.  \n",
    ">    And all data are inaccurate.  \n",
    ">    What are we to do?  \n",
    ">    We must be sure to remain uncertain. \n",
    "\n",
    "-- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* \n",
    "\n",
    "#### What is uncertainty and where does it come from?\n",
    "Uncertainty exists in all systems that make contact with the real world. The physical world is not the domain of absolute logical truth, and the human social world is even less so. \n",
    "\n",
    "In interaction, we have, in the simplest case, two parties: \n",
    "\n",
    "* a brain embedded in a human embedded in a physical world\n",
    "* and software, embedded in computer hardware, embedded in the same physical world. \n",
    "\n",
    "\n",
    "### Epistemic, aleatoric and approximation\n",
    "\n",
    "We can separate out some *types* of uncertainty:\n",
    "\n",
    "* Epistemic uncertainty is uncertainty about what we know (hence epistemic) arising from the limitations of our knowledge (as encoded by a model). For example, we might model... [TODO]\n",
    "* Aleatoric uncertainty is that which arises from (presumed) randomness in the world. If I toss a coin, my uncertainty about which side lands face up is aleatoric. This type of uncertainty cannot be resolved by better modelling, more data, etc.; it is irreducible.\n",
    "\n",
    "* Approximation\n",
    "\n",
    "### The wonder-sludge\n",
    "\n",
    "\n",
    "\n",
    "## What is a Bayesian [II]?\n",
    "\n",
    "A Bayesian:\n",
    "\n",
    "* Represents, preserves and manipulates uncertainty about unknown states. Uncertainty is **first-class**.\n",
    "* Builds generative models of the phenomena under consideration, that simulate plausible observations.\n",
    "* Reasons about the unknown parameters that modulate the behaviour of those generative models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Probability\n",
    "\n",
    "\n",
    "### What is probability?\n",
    "\n",
    "A fraught philosophical question! See the references for debates on this topic. We'll make some uncontroversial statements, then an *interpretation* of probability.\n",
    "\n",
    "**Probability, as we shall use it, is simply an extension of ordinary logic to uncertain situations.**\n",
    "\n",
    "\n",
    "#### Basic facts\n",
    "\n",
    "* We associate numbers (probabilities) with sets (*events*), written $P(A)$to mean \"probability of event A\".\n",
    "* Probabilities are non-negative and cannot exceed 1: $0 \\leq P(A) \\leq 1$ \n",
    "* A probability distribution associates a set of distinct *outcomes* to probabilities. $P(X=x)$ meaning the probability that variable $X$ takes on outcome $x$.\n",
    "* An *event* is any set of outcomes. The set of all outcomes in our \"model\" is the *sample space*.\n",
    "* The probability of all possible outcomes in a distribution sums to 1 exactly.\n",
    "* The probability of any set of disjoint events that cover all outcomes is therefore also 1.\n",
    "* => If A and B are events $P(A \\lor B) = P(A) + P(B) - P(A\\land B)$ (sum rule; A and B are sets of outcomes)\n",
    "* => If A has probability $P(A)=P(X \\in A)$, $P(¬A)=P(X \\notin A)=1-P(A)$\n",
    "* The probability of two *independent* events A and B is $P(A \\land B) = P(A)P(B)$\n",
    "* The probability of A *given we know that* an event B is true is written $P(A|B) = P(A \\land B)/P(B)$\n",
    "* The probability of P(A|B) is **not** in general P(B|A).\n",
    "* $P(A|B) = P(B|A)P(A) / P(B)$ (Bayes' Rule)\n",
    "* $P(B) = \\sum_B P(B|A)P(A)$ \n",
    "\n",
    "---\n",
    "\n",
    "I grab a single coin from my pocket. We assume they are all Euros. That's our space of possibilities.\n",
    "\n",
    "* The probability of the coin being worth >50c is an *event*; perhaps $P(v>0.5)=P(v \\in {1.0, 2.0})=0.33$\n",
    "* Regardless of what distribution of coins I have in my pocket, it cannot be less than impossible to pick a specific coin, nor more than certain.\n",
    "* A probability distribution might map each coin (outcome) to a probability, a real number in [0,1]; for example:\n",
    "    * [REPLACEWITHIMAGE]\n",
    "    * P(v=0.01) = 0.02\n",
    "    * P(v=0.02) = 0.05\n",
    "    * P(v=0.05) = 0.1\n",
    "    * P(v=0.10) = 0.1\n",
    "    * P(v=0.20) = 0.2\n",
    "    * P(v=0.50) = 0.2\n",
    "    * P(v=1.00) = 0.3\n",
    "    * P(v=2.00) = 0.03\n",
    "* A coin might be worth less than 10 cents $P(v<0.1) = P(v \\in \\{0.01, 0.02, 0.05\\})$ or being gold-coloured $P(v \\in \\{0.2, 0.5\\})$, or being 1 euro $P(v \\in \\{1.0\\})$. These are all events.\n",
    "* Since we must draw exactly one coin, the event that includes all coins must have probability 1.0.\n",
    "* The probability of a coin being less than 20c or more than *or* equal to 20c must also be 1.0, by the same logic (we cover every outcome exactly once). $P(v < 0.2 \\lor v\\geq 0.2) = P(v<0.2) + P(v \\geq 0.2) = 1.0$\n",
    "* The probability of a coin being not gold coloured in one minus the probability of being gold coloured $P(gold) + P(¬gold) = 1$, $P(¬gold) = 1 - P(gold)$\n",
    "* The probability of a coin being less than 50c or being gold-coloured is $P(v < 0.5 \\lor v \\in \\{0.2, 0.5\\}) = P(v<0.5) + P(v \\in \\{0.2, 0.5\\}) - P(v<0.5 \\land v \\in \\{0.2, 0.5\\}) = P(v<0.5) + P(v \\in \\{0.2, 0.5\\}) - P(v=0.5)$ -- we compensate for \"double counting\" the overlap\n",
    "* The probability that I draw a coin that is gold coloured and it is a Spanish coin is $P(gold \\land Spanish) = P(gold)P(Spanish)$, assuming these are independent (e.g. I don't specially collect gold-coloured Spanish euro coins)\n",
    "    * But the probability that I draw coin that is copper coloured and Finnish is **not** $P(copper)P(Finnish)$ (because 1c and 2c Finnish coins are very rare)\n",
    "* The probability that I draw a gold coin given that the coin is less than a euro is $P(gold | v<1.0) = P(v \\in \\{0.1, 0.2, 0.5\\}) / P(v \\in \\{0.01, 0.02, 0.05, 0.1, 0.2, 0.5\\}) \\approx 0.746...$\n",
    "* The probability that I draw a coin less than a euro given that it is gold is $P(v < 1.0 | gold) = P(v \\in \\{0.1, 0.2, 0.5\\}) / P(v \\in \\{0.1, 0.2, 0.5\\}) = 1.0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Random variables and distributions\n",
    "\n",
    "* A **random variable** $X$ is a variable whose value is not known, but whose possible values *are* known, and how likely those values are is also known. Probability theory allows us to manipulate random variables without having to assign them a specific value.\n",
    "* A **probability distribution** $P(X=x)$ associates a random variables outcomes to probabilities. It encodes the plausibility of a variable's outcomes.\n",
    "* A **probability mass function** $f_X(x)$ is a function that yields probabilities as a function of outcomes.\n",
    "* If we have uncountable outcomes (like real numbers), we instead use a **probability density function** $f_X(x)$, which just guarantees the rules above hold for dense subsets of the outcomes, even if they can't hold for individual outcomes.\n",
    "    * Densities are not probabilities! They are non-negative, but can be greater than 1; the *integral* of a density over some domain *is* a probability. (e.g. $P(1\\leq age \\leq 2) = \\int_1^2 f_X(age) dx$ over the interval [1, 2] of $\\mathbb{R}$) \n",
    "\n",
    "A random variable could represent:\n",
    "\n",
    "\n",
    "[IMAGEHERE]\n",
    "* whether or not a user is paying attention (discrete: binary), over the set of outcomes $\\{\\text{attending}, \\text{ignoring}\\}$; \n",
    "* the page of a document a user is reading $\\{1,2,3,\\dots\\}$ (discrete); \n",
    "* the length of a user's arm (continuous), over the set of outcomes $\\real$; \n",
    "* the gaze angle of a user's pupil with respect to a screen (continuous, multi-dimensional), over the set of outcomes $\\real^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Distributions\n",
    "A **probability distribution** defines how likely different states of a random variable are. \n",
    "\n",
    "We can see $X$ as the the *experiment* and $x$ as the *outcome*, with a function mapping every possible outcome to a probability. \n",
    "\n",
    "> Be careful: these are *notional* experiments, not real ones. They might involve things that are in the past, or have no randomness. They are subjective experiments from the perspective of an agent. \n",
    "\n",
    "$$\n",
    "P(A),\\  \\text{the probability of an event A}, \\text{equivalent to} P(X \\in A)\\\\\n",
    "P(X=x),\\  \\text{the probability of random variable X taking on value x}\\\\\n",
    "P(X),\\  \\text{shorthand for distribution of X }\\\\\n",
    "$$\n",
    "\n",
    "## Philosophy\n",
    "\n",
    "We will use the subjective Bayesian interpretation of probability. This has a simple statement but deep implications.\n",
    "\n",
    "* Probability is a *degree of belief*.\n",
    "* We express how strongly we believe something to be true with a probability. \n",
    "* We encode all beliefs as probability distributions. It's probabilities all the way down.\n",
    "* We manipulate all beliefs via the rules above. This naturally includes all of classical logic, where P=0 is False and P=1 is True.\n",
    "* We might expect that these probabilities would be *consistent* with observed relative frequencies of some random repeated process, but **that's not our definition of probability**. We do not invoke the mystical infinitely repeated identical experiments!\n",
    "* It's completely fine to make statements like \"the probability that it is raining right now\", \"the probability that 2^10^10^10-1 is prime\" or \"the probability that the 2012 Olympics was in London\" (think carefully about what the probability might be!)\n",
    "* Because this form of probability theory is merely a logic of uncertain beliefs, we must always reason from some starting point. Rather than **axioms**, as in classical logic, we instead begin from **priors**, associating beliefs to probabilities at the start of a reasoning process.\n",
    "\n",
    "> We shall move from \"what proportion of times will I draw a 50c coin from my pocket?\" to \"what do you *believe* about my having a 50c coin?\"\n",
    "\n",
    "## Computer science\n",
    "\n",
    "* Probability is a **universal language** for expressing uncertain states.\n",
    "* Anything that \"speaks probability\" can be plugged into any other component that also does so.\n",
    "    * (at least if we can map sample spaces onto each other)\n",
    "* Probability is easy to encode in data structures for finite, discrete problems and the algorithms are simple\n",
    "    * A hash table/dictionary or plain array can do most of the work\n",
    "* It is much harder in continuous, multi-dimensional spaces or those with exotic topology.\n",
    "    * Consequently, we will virtually always have to **approximate** probabilities in these situations.\n",
    "    * And we will have to build and use approximation algorithms to do the hard work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Probability mass functions and probability density functions\n",
    "\n",
    "### Inference\n",
    "\n",
    "We seek a logical process to perform inference: the deduction of the hidden from the seen. We seek to do so under uncertainty, where we do not deal in absolutes of truth and falsity.\n",
    "\n",
    "* Our primary tool is Bayes Rule. \n",
    "* The ability to do inference is derived from the ability to say: how likely is some unseen X given we saw Y?\n",
    "    * \"How likely is it that a coin is more than five years old given it is heavily corroded?\"\n",
    "        * I can see corrosion; I can't see age.\n",
    "    * We can answer that as:\n",
    "        * It is the probability that we'd observe Y if X were true; multiplied by how likely we *already* believe X to be true; and normalised so that the probability for each possible X sums up to 1.\n",
    "        * $P(X|Y) = P(Y|X)P(X) / P(Y) = P(Y|X)P(X) / \\sum_X P(Y|X)P(X)$\n",
    "        * $P(X|Y) \\propto P(Y|X)P(X)$ if all we care about is how *relatively* likely each possible $X$ is (not how *absolutely* likely it is)\n",
    "    * These parts have names:\n",
    "        * `posterior = likelihood * prior / evidence`\n",
    "        * **posterior** The probability of beliefs about $X$ after having observed $Y$\n",
    "        * **likelihood** How likely $Y$ is to be observed under any possible hypothesised $X$\n",
    "        * **prior** How currently likely $X$ is before observing $Y$\n",
    "        * **evidence** How likely $Y$ is to be observed regardless of what hypothesis we make about $X$\n",
    "\n",
    "* The likelihood of X, written $L(X)$ is how likely $X$ is to be observed under a particular model. Often written $L(X|\\theta)$ to mean \"the likelihood of X under some specific parameters \\theta\".\n",
    "    * Probabilities speak of the \"future\", of the relative propensity for unobserved outcomes to occur.\n",
    "    * Likelihoods speak of the \"past\", of observed states. They are just a function of observations/data, and they tell us how likely observed outcomes are under some assumption.\n",
    "    * The likelihood is $L(x) = f_X(x)$, just the mass/density evaluated for a specific outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and inverse probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Bayesian? [III]\n",
    "\n",
    "A **Bayesian**:\n",
    "\n",
    "* Represents belief exclusively using probability distributions and conducts all computation about beliefs via the logic of probability.\n",
    "* Reasons from hypotheses about the world to the evidence that those hypotheses would generate (via a data generating process).\n",
    "* Updates belief using Bayes' Rule, combining a prior belief with observed evidence to deduce new beliefs.\n",
    "* Infers conditional distributions -- posterior distributions -- over unseen parameters of the DGP.\n",
    "\n",
    "Given a parameterised simulator that approximates the problem we are interested in, and some idea about what values these parameters could take on (expressed as a prior probability distribution) we can then use evidence to make a Bayesian update to concentrate a belief distribution on more likely parameter configurations --- a posterior probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A grid model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import itertools\n",
    "\n",
    "\n",
    "class PMF:\n",
    "    def __init__(self, pmf):\n",
    "        # p: outcome -> value\n",
    "        self.pmf = pmf\n",
    "\n",
    "    def proper(self):\n",
    "        assert sum(self.pmf.values())==1.0, \"Probabilities don't sum to 1.0\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return pprint.pformat(self.pmf)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(self, outcome):\n",
    "    return self.pmf[outcome]\n",
    "\n",
    "\n",
    "PMF.likelihood = likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lik(self, outcomes):\n",
    "    return sum([np.log(self.likelihood(o)) for o in outcomes])\n",
    "\n",
    "\n",
    "PMF.log_lik = log_lik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(self, n):\n",
    "    return list(np.random.choice(list(self.pmf.keys()), p=list(self.pmf.values()), size=n))\n",
    "\n",
    "\n",
    "PMF.sample = sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def from_empirical(observations):\n",
    "    c = Counter(observations)\n",
    "    total = sum(c.values())\n",
    "    return PMF({outcome: count / total for outcome, count in c.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect(self, g=lambda x: x):\n",
    "    return sum(g(outcome) * p for outcome, p in self.pmf.items())\n",
    "\n",
    "\n",
    "PMF.expect = expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(self):\n",
    "    return -sum(p * np.log2(p) for p in self.probs)\n",
    "\n",
    "\n",
    "PMF.entropy = entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes(self, likelihood):\n",
    "    unnorm = {k: self[k] * likelihood[k] for k in self.pmf}\n",
    "    s = sum(unnorm.values())\n",
    "    return PMF({unnorm[k] / s for k in unnorm})\n",
    "\n",
    "\n",
    "PMF.bayes = bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bayes_table(self, likelihood):\n",
    "    unnorm = {k: self.pmf[k] * likelihood.pmf[k] for k in self.pmf}\n",
    "    s = sum(unnorm.values())    \n",
    "    posterior =  PMF({k:unnorm[k] / s for k in unnorm})\n",
    "    df = pd.DataFrame(zip(self.pmf.values(), likelihood.pmf.values(), unnorm.values(), posterior.pmf.values()), columns = [\"Prior\", \"Likelihood\", \"Unnormalised\", \"Posterior\"])\n",
    "    return df \n",
    "\n",
    "\n",
    "PMF.bayes_table = bayes_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = PMF({1:0.5, 2:0.5})\n",
    "likelihood = from_empirical([1,2,2])\n",
    "prior.bayes_table(likelihood)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint(self, other):\n",
    "    \"\"\"Only valid for two *independent* PMFs!\"\"\"\n",
    "    return PMF(\n",
    "        {\n",
    "            (a, b): p_a * p_b\n",
    "            for (a, p_a), (b, p_b) in itertools.product(\n",
    "                self.pmf.items(), other.pmf.items()\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "PMF.__matmul__ = joint\n",
    "\n",
    "PMF({1: 0.2, 2: 0.8}) @ PMF({\"cat\": 0.1, \"dog\": 0.9})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal(self, mask):\n",
    "    acc = {}\n",
    "    for outcome, p in self.pmf.items():\n",
    "        removed = tuple([component for elt, component in zip(mask, outcome) if mask])        \n",
    "        acc[removed] = acc.get(removed, 0) + p\n",
    "    return PMF(acc)\n",
    "\n",
    "\n",
    "PMF.marginal = marginal\n",
    "\n",
    "p = PMF({1: 0.2, 2: 0.8}) @ PMF({\"cat\": 0.1, \"dog\": 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditional\n",
    "def conditional(self, n):\n",
    "    p_B = self.marginal(n)\n",
    "\n",
    "    for outcome, p in self.pmf.items():\n",
    "        p / p_B.pmf[outcome[n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Using all of the above to do basic inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow worlds\n",
    "\n",
    "[SHADOW_WORLRD_IMAGE]\n",
    "\n",
    "### (Prior, posterior) x (parameter, predictive)\n",
    "\n",
    "It's important to keep the various elements of a Bayesian model distinct.\n",
    "\n",
    "#### Over parameters (inference)\n",
    "* **Prior** a distribution over unknown parameters before some observations\n",
    "* **Posterior** a distribution over unknown parameters after observations\n",
    "\n",
    "#### Over observations (simulation)\n",
    "* **Prior predictive** a distribution over observations *that our model would generate* under the priors.\n",
    "* **Posterior predictive** a distribution over observations *that our model would generate* under the posterior.\n",
    "\n",
    "### Sequential (\"recursive\") updates\n",
    "\n",
    "The names *prior* and *posterior* can refer to distinct parts of a modelling process (e.g. I elicit a prior from an expert, then run an experiment to observe data that I use to compute a posterior). But the naming of prior and posterior is *purely relative*! \n",
    "\n",
    "It's completely fine for a prior for one step of an inference process to become the posterior for another step. Everything is just probability distributions, which are a universal language -- everything plugs together (over the same sample space, anyway).\n",
    "\n",
    "## Fusing freely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Inference approaches\n",
    "\n",
    "### The process of eliciting, encoding and validating\n",
    "\n",
    "#### Elicit and encode\n",
    "\n",
    "#### Validate\n",
    "\n",
    "\n",
    "### Concrete algorithms\n",
    "\n",
    "#### MCMC\n",
    "\n",
    "#### Variational\n",
    "\n",
    "#### Exact\n",
    "\n",
    "## What is a Bayesian [IV]\n",
    "\n",
    "* Applies algorithms such as MCMC or variational inference to infer probability distributions over hidden states from observed data.\n",
    "* Implements data generating processes as computational simulators of expected phenomena, and can simulate concrete implications of hypotheses.\n",
    "* Reports and summarises inferences via approximations that are computationally tractable (e.g. via random samples)\n",
    "* Is typically concerned with *expectations* of a score function applied to a distribution, such as utility.\n",
    "* Freely fuses evidence from any source, in the past, present or future.\n",
    "\n",
    "\n",
    "\n",
    "### Why is this Computational HCI?\n",
    "\n",
    "* We build **statistical models** of user behaviour, and estimate parameters of that model from quantitative observations of data. \n",
    "* This is a **model-led approach** which has a strong mathematical underpinning and many powerful algorithms which can be brought to bear.\n",
    "* This is **robust** (it appropriately represents uncertainty) and **generative** (it can simulate behaviour compatible with observations).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2eddf4f4d750c89334ec483a20beff3a977ef7807bc2815549a2bacb7799a306"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
