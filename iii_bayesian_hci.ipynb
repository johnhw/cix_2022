{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III: Bayesian HCI: A review and a reflection\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "You will understand:\n",
    "\n",
    "* The loops and stakeholders in interaction design: modelling, design, interaction and analysis\n",
    "* Key themes of Bayesian approaches in HCI\n",
    "* 1. How to apply Bayesian models at interaction time: **inference of intent**\n",
    "* 2. Design time optimisation with uncertainty: **Bayesian optimisation**\n",
    "* 3. How to analyse experimental evaluations: **Bayesian statistics for empirical analyses**\n",
    "* 4. How to model cognitive process using Bayesian models: **Bayesian cognitive modelling**\n",
    "* 5. How to apply interaction to problems of Bayesian modelling\n",
    "\n",
    "In each of the numbered sections, we'll do this with a short discussion and a two-minute review of two or three relevant papers from the literature.\n",
    "\n",
    "## The times, the players and the loops\n",
    "\n",
    "### An HCI process\n",
    "What goes on in HCI? An old-school traditional HCI process might unfold like this:\n",
    "\n",
    "* A **psychologist** builds models of how people perceive and act in the world, and how they understand and might conceive of interfaces.\n",
    "* A **designer** thinks about a problem and uses tools like use cases, personas, scenarios to conceptualise how an interface might used; and prototyping tools (like paper prototypes) to decide how that interface should be used.\n",
    "* An interface is implemented. When it is in operation, a user is engaged in a **control loop** where the interface reacts to inputs from sensors, changes internal states, and updates outputs on displays.\n",
    "* To determine how well this interface works, an **evaluation** is conducted to analyse the way in which the interface is used, how successfully it is operated, how users feel about different aspects, etc.\n",
    "\n",
    "\n",
    "### The times and the loops\n",
    "This gives rise to four distinct **times**:\n",
    "\n",
    "* **Modelling time** which models, in the general case, human behaviour in the presence of interactive systems;\n",
    "* **Design time** where a specific instantiation of an interface is arrived at by some design process;\n",
    "* **Interaction time** where specific user goals at an instant of time are serviced via an interface;\n",
    "* **Analysis time** where the efficacy of the interface is reviewed and analysed.\n",
    "\n",
    "None of these are simple feed-forward processes; all would typically involve *feedback*; we might test prototypes to refine designs or to build better models of interface usage.\n",
    "\n",
    "We'll talk through how each of these broad categories can be addressed from a Bayesian framework, and illustrate a few papers from the literature that do so.\n",
    "\n",
    "### Themes\n",
    "\n",
    "When we talk through these, there are some key themes of \"Bayesianism\" to look for:\n",
    "\n",
    "* Models: what form do models take? What are the parameters?\n",
    "* Inference: how is it achieved? What computations give us posteriors?\n",
    "* Uncertainty: how is represented and what is used for? Why is uncertainty valuable in this context?\n",
    "* Priors: where do they come from and how are they specified?\n",
    "\n",
    "### Commonalities\n",
    "A Bayesian approach:\n",
    "* *always* involves manipulating probability distributions over unobserved parameters\n",
    "* *always* involves a movement from prior to posterior guided by belief\n",
    "* *always* requires defining a data generating process\n",
    "* *always* preserves uncertainty (to some degree, usually limited by computation)\n",
    "* *always* has some computational struggles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## In: In-the-loop: Bayesian interaction\n",
    "\n",
    "### Summary\n",
    "We infer distributions over intentions during an interaction, fusing together evidence from multiple sources, and over time. We need models of behaviour/sensing/display, representations of probability distributions that are compatible with our UI software, and techniques for preserving and reflecting probabilistic state.\n",
    "\n",
    "### Motivation\n",
    "Adding probabilistic Bayesian inference in the interaction loop can make interaction more robust, rational and efficient.\n",
    "\n",
    "* **Robust** means that the interaction should reliably coincide with intention, even in the presence of disturbance;\n",
    "* **Rational** means that the actions should be taken that accurately reflect both certainty and utility;\n",
    "* **Efficient** means that action should coincide with intention with a minimum of time, mental or physical effort expended.\n",
    "\n",
    "This is particularly salient when there is a large control:action disparity.\n",
    "* For example: the interaction technique is marginally effective (e.g. in assistive technology for text entry) \n",
    "* For example: the space of possible actions is huge (e.g. a search engine)\n",
    "\n",
    "### Model\n",
    "\n",
    "A human interacting with a computer. We can see this several ways:\n",
    "\n",
    "[IMAGE]\n",
    "\n",
    "* Communication: users encode selections to be packaged over a motor channel and then a sensor channel. These are decoded into state changes.\n",
    "    * Essentially feed-forward; low-latency, high mental cost, high-bandwidth. Domain of pattern recognition approaches.\n",
    "* Control: users drive a system into a desired equilibrium by feedback control, through a motor/sensor channel, via a mediating mechanism (like a cursor), and back through a perceptual channel.\n",
    "    * Essentially closed-loop. Low mental cost, low bandwidth. Domain of traditional UI components.\n",
    "* Inference: A system infers what a user might want to happen, based on observed evidence, and designs experiments via the feedback channel to optimally acquire more.\n",
    "    * Closed-loop or feed-forward. Domain of probabilistic interfaces.\n",
    "\n",
    "\n",
    "##### Interaction as inference\n",
    "If we view interaction as inference of intention, there are three elements:\n",
    "* **Interaction is inference**; it is the process of inferring a distribution over a hidden variable: what the user wants a system to do. \n",
    "* **Observations are indirect, noisy and incomplete** What a system sees is a distorted and incomplete representation of user actions in the world, which are in turn a noisy representation of internal intentions (your hand does not always go where you want it...)\n",
    "* **Interaction occurs over time** Interaction is a *process* that evolves over time. Information flow is not instantaneous. Observations must be fused together to update beliefs.\n",
    "\n",
    "### Approach\n",
    "\n",
    "* Inference approach: Model the system's uncertainty over user intentions as a probability distribution, update via Bayes' rule. $P(\\text{intention}|{input})$\n",
    "    * What inputs would we *expect* to see, given hypothesised intentions and their prior likelihood?\n",
    "        * For example, what mouse trajectories would we expect to see, given that a user was pointing a specific icon?\n",
    "    * If still unresolved, provoke a response that will maximise the information gain (change in entropy).\n",
    "        * For example, move one of the two most likely icons and see if the user compensates.\n",
    "\n",
    "We'll look at a **Bayesian** approach to modelling human computer interaction, where we explicitly model what might be going on inside a user's mind and use Bayesian methods to try and perform \"optimal mindreading\". \n",
    "<img src=\"imgs/brain_inference.png\" width=\"70%\">\n",
    "\n",
    "### Models\n",
    "This view on interaction sees user intentions as **unknown values** which are partially observed through inputs. The time series of inputs from the user give a partial, noisy, incomplete view of intention inside the user's head, along with a great deal of superfluous information. \n",
    "\n",
    "We try and infer intention *generative model* which is a simplified representation of intention and how it is mediated and transformed by the world. The stronger model we have available, the more effectively we can infer intention.\n",
    "\n",
    "> In this view, improving interaction (or at least *input*) comes down to more efficiently concentrating probability density where a user wants it. A better pointing device reduces uncertainty faster; a better display helps a user understand how best to target future actions to concentrate belief as desired; a better model of the user intentions concentrates belief with less explicit effort on the part of a user.\n",
    "\n",
    "<img src=\"imgs/contraction_probability.png\" width=\"70%\">\n",
    "\n",
    "#### Partitioning the inferred variables\n",
    "\n",
    "We can further partition the problem. The causes of observed evidence can be factored, for example, into:\n",
    "\n",
    "* **Mind state** The parameters of the intentions that generate the behaviour: what menu option does the user want?\n",
    "* **World state** The parameters of the motor system that generate movement: where is the user's hand?\n",
    "* **Sensor state** The parameters of the sensing system that generates signals: what is the camera matrix?\n",
    "\n",
    "$$P(X_{\\text{intention}}, X_{\\text{motor}}, X_{\\text{sensing}}|Y)$$\n",
    "\n",
    "[Betancourt's article on probabilistic modeling](https://betanalpha.github.io/assets/case_studies/modeling_and_inference.html) expresses these ideas in terms of the \"phenomenon\" (intention), \"environment\" (motor/world system) and \"probe\" (sensing/interface context).\n",
    "\n",
    "\n",
    "### Uncertainty\n",
    "* Input from a human user will often be ambiguous, at least at some point in time. This might be because of:\n",
    "    * Genuine noise in the sensing that disturbs the intended control;\n",
    "    * User confusion, error or changing intentions;\n",
    "    * Partial and incomplete evidence of intention from sensing;\n",
    "    * Inaccurate models of behaviour given intention.\n",
    "* Failure to represent uncertainty means actions might be taken without sufficient evidence, or require unreasonable quantities of evidence to actuate.\n",
    "* Balancing the information flow requires a proper accounting of uncertainty.\n",
    "\n",
    "\n",
    "### Priors\n",
    "        \n",
    "\n",
    "Diagram\n",
    "### Example\n",
    "### Papers\n",
    "#### Paper a: AnglePose\n",
    "#### Paper b: Dasher\n",
    "#### Paper c: BIGNav\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Before: Bayesian optimisation at design time\n",
    "\n",
    "\n",
    "### Motivation\n",
    "Design by hand-engineering relies on idiom and experience, which may not be optimal or agile enough to adapt to new contexts, such as new devices or specific user groups. Automatic optimisation of the specific parameterisation of an interface can address this *but* acquiring data from users to fine-tune is very expensive and very noisy. Bayesian optimisation is a sample-efficient way to tune designs by constructing a distribution over proxy objective functions.\n",
    "\n",
    "#### Approach\n",
    "\n",
    "\n",
    "* Uncertainty: \n",
    "\n",
    "\n",
    "Motivation\n",
    "Diagram\n",
    "### Example\n",
    "### Papers\n",
    "#### Paper a: Antti\n",
    "#### Paper b:\n",
    "#### Paper c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## After: Bayesian analysis of empirical work\n",
    "### Introduction\n",
    "When we evaluate how an interface works, we typically rely on statistical tools to analyse quantitative results. Even better, we'd hope to use statistical tools to *design* the analyses\n",
    "that we intend to perform: statistics starts before the experiment, not afterwards!\n",
    "\n",
    "Statistical analysis in HCI are common -- just look at any CHI paper -- but they are often inappropriate or flawed. Almost all HCI uses classical frequentists statistics adopted from psychology. Frequentist statistics include things like t-tests, ANOVAs, Mann-Whitney tests, and so on. Frequentist statistics *are not wrong*; they are perfectly mathematically valid and sometimes useful techniques. But they are most certainly not the only way to do statistics and rarely the appropriate methods for HCI.\n",
    "\n",
    "> Some authors (e.g. E. T. Jaynes or Aubrey Clayton) would argue that all of frequentists statistics is useless rubbish and that Bayesian methods are the only valid approach to analysing data. \n",
    "> They might be right. \n",
    "\n",
    "\n",
    "### Motivation\n",
    "Why do frequentist statistics fail to do what we want to do? How do Bayesian methods help? And what are the trade-offs?\n",
    "\n",
    "> Do we want to compare two blocks of observations, apply a \"black box\" algorithm, and make statements about how likely the variation is to be \"random\" as opposed to \"true\"?\n",
    "\n",
    "#### False dichotomy and backwards questions\n",
    "* Frequentist statistics often force us into dichotomous decisions: is A (statistically significantly) better than B. \n",
    "* But *constructing* a B to compare with may not make much sense. At the very least, it leaves make pointwise comparisons to baselines.\n",
    "* This mode of thought permeates how we think about experimental work in HCI **but it is not necessary**.\n",
    "* Dichotomous analyses *are* appropriate if you want to make comparisons to a baseline, in controlled studies, where effects are large and false positives are important.\n",
    "    * For example, in randomised controlled trials for efficacy of drugs.\n",
    "* Frequentist statistics can't answer many questions we'd like to know the answer to; \"how likely is it that A is twice as efficient as B\"? \n",
    "    * **Our analysis procedures should answer the questions we want to know, not define the questions we are allowed to ask!**\n",
    "* Frequentist statistics typically give us a single estimate but not uncertainty about inference.\n",
    "    * FS can make only make uncertainty quantifications about observations, not parameters.\n",
    "    * But our questions are usually about parameters!\n",
    "\n",
    "#### Application and interpretation\n",
    "* Frequentist statistics produce quantities like p-values and confidence intervals. **These are valid but very hard to interpret!**\n",
    "    * Q: define one of these terms *correctly*    \n",
    "\n",
    "* Frequentist statistics are easy to misuse; great care is needed make sure you account for multiple testing, researcher degrees of freedom, stopping rules to preserve the false positive rate of testing procedures.\n",
    "* Frequentist statistics come in pre-packaged forms (e.g. ANOVA). These have to be slotted in. This leads to several problems:\n",
    "    * You must make the choice of approach intelligently among a zoo of tests and procedures. But you cannot adjust any of the details to fit your problem.\n",
    "    * No modelling is required and so you can avoid defining a good data generating process -- which means you are likely to do silly things.\n",
    "* No prior information is explicitly defined. That seems \"objective\", but it hides that every frequentist approach makes *hidden* assumptions equivalent to priors.\n",
    "    * In other words, you get a one-size-fits-all prior that is unlikely to match your true priors, and there is nothing you can do about it.\n",
    "\n",
    "\n",
    "#### Other issues\n",
    "* Frequentist methods are typically used because of tradition. This is not a good reason.\n",
    "    * Bayesian statistics are not widely understood.\n",
    "    * Researchers are reluctant to admit that much of published statistics might be dubious.\n",
    "    * Sotfware and tooling doesn't make it easy to Bayesian analysis.\n",
    "    * Philosophical debates still rage about Bayesian vs. frequentist models. Some are still cautious about Bayesian methods (or aligned with the dark side).\n",
    "* Computational issues used to make Bayesian methods impractical. This isn't a good excuse these days.\n",
    "* Priors can be controversial. You can obviously change what you assume to change what you believe in the light of evidence.\n",
    "    * But the counter-argument is that *expliclity stating* your assumptions (as priors) is the right way to be honest; a procedure can't guarantee honesty but it can hide deception.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Diagram\n",
    "### Example\n",
    "### Papers\n",
    "#### Paper a: Kay et. al.\n",
    "#### Paper b: Prior selection\n",
    "#### Paper c: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## About: Bayesian models of cognition and behaviour\n",
    "### Introduction\n",
    "How do we start to build interfaces? In the old days, hardware and computational power dictated many of the constraints.\n",
    "![Ye olde interaction experience.]()\n",
    "Even so, ancient mainframes still  had to group their switches logically, label them, and lay them out for ergonomic reachability. \n",
    "To build interfaces we need to understand how humans behave. Human behaviour is the key constraint that defines interaction. We need models of how humans behave. \n",
    "\n",
    "Some HCI relies on human experience of behaviour (\"designer's intuition\"), heuristics that formalise these experiences, and repeated evaluation as a crutch to stitch up the mismatches. Computational interaction rejects this approach, and puts computational models first. This means we have to have actionable simulators of aspects of human behaviour that can be applied to interface design problems.\n",
    "\n",
    "Some human simulation problems are tricky but largely in the realm of the observable and relatively certain, like simulating reach volumes from biomechanics. But others, especially those that involve cognition, are very hard to construct. Cognitive processes are:\n",
    "\n",
    "* weakly observable -- we have essentially no instruments to act upon them and limited modes of observation.\n",
    "* potentially highly variable among the population and even within an individual\n",
    "* Cognition is stochastic in production of evidence (\"same\" mental state => different observed outcomes).\n",
    "* very complex in nature. A linear system probably won't suffice!\n",
    "\n",
    "Motivation\n",
    "Diagram\n",
    "### Example\n",
    "### Papers\n",
    "#### Paper a: Visualisation (yeal)\n",
    "#### Paper b: ABC Antti\n",
    "#### Paper c: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With: Interaction with Bayesian models\n",
    "### Introduction\n",
    "Let's turn the tables. What can HCI offer Bayesian modelling? How could HCI help:\n",
    "\n",
    "* create Bayesian models?\n",
    "* validate and verify Bayesian models?\n",
    "* visualise, explore and explain their implications and consequences?\n",
    "\n",
    "> Bayesian modelling is often seen as hard, and the models as complex and inscrutable. This isn't \"really\" true, but\n",
    "> there lots to be done to make the \"real\" complexity manageable. These are problems of interaction between users and models.\n",
    "\n",
    "#### End users\n",
    "\n",
    "\n",
    "Motivation\n",
    "Diagram\n",
    "### Example\n",
    "### Papers\n",
    "#### Paper a:\n",
    "#### Paper b:\n",
    "#### Paper c:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
