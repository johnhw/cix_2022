{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III: Bayesian HCI: A review and a reflection\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "You will understand:\n",
    "\n",
    "* The loops and stakeholders in interaction design: modelling, design, interaction and analysis\n",
    "* Key themes of Bayesian approaches in HCI\n",
    "* 1. How to apply Bayesian models at interaction time: **inference of intent**\n",
    "* 2. Design time optimisation with uncertainty: **Bayesian optimisation**\n",
    "* 3. How to analyse experimental evaluations: **Bayesian statistics for empirical analyses**\n",
    "* 4. How to model cognitive process using Bayesian models: **Bayesian cognitive modelling**\n",
    "* 5. How to apply interaction to problems of Bayesian modelling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The times, the players and the loops\n",
    "![The times, the players and the loops](imgs/bayesian_loops.png)\n",
    "\n",
    "### An HCI process\n",
    "What goes on in HCI? An old-school traditional HCI process might unfold like this:\n",
    "\n",
    "* A **psychologist** builds models of how people perceive and act in the world, and how they understand and might operate interfaces.\n",
    "* A **designer** thinks about a problem and uses tools like use cases, personas, scenarios to conceptualise how an interface might used; and prototyping tools (like paper prototypes) to decide how that interface should be used.\n",
    "* An interface is implemented. When it is in operation, a user is engaged in a **control loop** where the interface reacts to inputs from sensors, changes internal states, and updates outputs on displays.\n",
    "* To determine how well this interface works, an **evaluation** is conducted to analyse the way in which the interface is used, how successfully it is operated, how users feel about different aspects, etc.\n",
    "\n",
    "\n",
    "### The times and the loops\n",
    "This gives rise to four distinct **times**:\n",
    "\n",
    "* **Modelling time** which models human behaviour in the presence of interactive systems;\n",
    "* **Design time** where a specific instantiation of an interface is arrived at by some design process, informed by modelling;\n",
    "* **Interaction time** where specific user goals at an instant of time are serviced via an interface;\n",
    "* **Analysis time** where the efficacy of the interface is reviewed and analysed.\n",
    "\n",
    "None of these are simple feed-forward processes; all would typically involve *feedback*; we might test prototypes to refine designs or to build better models of interface usage.\n",
    "\n",
    "### Themes\n",
    "\n",
    "When we talk through these, there are some key themes of \"Bayesianism\" to look for:\n",
    "\n",
    "* Models: what form do the data generating processes take? What are the parameters that can vary?\n",
    "* Inference: how is it achieved? What computations give us posteriors, and how is evidence brought into play?\n",
    "* Uncertainty: how is represented and what is used for? Why is uncertainty valuable in this context?\n",
    "* Priors: where do they come from and how are they specified?\n",
    "\n",
    "### Commonalities\n",
    "A Bayesian approach:\n",
    "* *always* involves manipulating probability distributions over unobserved parameters;\n",
    "* *always* involves a movement from prior to posterior guided by belief;\n",
    "* *always* requires defining a data generating process;\n",
    "* *always* preserves uncertainty (to some degree, usually limited by computation);\n",
    "* *always* has some computational struggles!\n",
    "\n",
    "\n",
    "### Structure\n",
    "\n",
    "In each sub-section, I'll:\n",
    "* outline the concepts and how Bayesian ideas apply\n",
    "* briefly discuss 2-3 papers from CHI or UIST that used these ideas in real research applications.\n",
    "* then we'll run through a self-contained live code example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In: In-the-loop: Bayesian interaction\n",
    "\n",
    "### Summary\n",
    "We infer distributions over intentions during an interaction, fusing together evidence from multiple sources, and over time. We need models of behaviour/sensing/display, representations of probability distributions that are compatible with our UI software, and techniques for preserving and reflecting probabilistic state.\n",
    "\n",
    "\n",
    "### Motivation\n",
    "Adding probabilistic Bayesian inference in the interaction loop can make interaction more robust, rational and efficient.\n",
    "\n",
    "* **Robust** means that the interaction should reliably coincide with intention, even in the presence of disturbance;\n",
    "* **Rational** means that the actions should be taken that accurately reflect both certainty and utility;\n",
    "* **Efficient** means that action should coincide with intention with a minimum of time, mental or physical effort expended.\n",
    "\n",
    "This is particularly salient when there is a large control:action disparity.\n",
    "* For example: the interaction technique is marginally effective (e.g. in assistive technology for text entry) \n",
    "* For example: the space of possible actions is huge (e.g. a search engine)\n",
    "\n",
    "### Model\n",
    "\n",
    "A human interacting with a computer. We can see this several ways:\n",
    "\n",
    "[IMAGE]\n",
    "\n",
    "* Communication: users encode selections to be packaged over a motor channel and then a sensor channel. These are decoded into state changes.\n",
    "    * Essentially feed-forward; low-latency, high mental cost, high-bandwidth. Domain of pattern recognition approaches.\n",
    "* Control: users drive a system into a desired equilibrium by feedback control, through a motor/sensor channel, via a mediating mechanism (like a cursor), and back through a perceptual channel.\n",
    "    * Essentially closed-loop. Low mental cost, low bandwidth. Domain of traditional UI components.\n",
    "* Inference: A system infers what a user might want to happen, based on observed evidence, and designs experiments via the feedback channel to optimally acquire more.\n",
    "    * Closed-loop or feed-forward. Domain of probabilistic interfaces.\n",
    "\n",
    "\n",
    "##### Interaction as inference\n",
    "If we view interaction as inference of intention, there are three elements:\n",
    "* **Interaction is inference**; it is the process of inferring a distribution over a hidden variable: what the user wants a system to do. \n",
    "* **Observations are indirect, noisy and incomplete** What a system sees is a distorted and incomplete representation of user actions in the world, which are in turn a noisy representation of internal intentions (your hand does not always go where you want it...)\n",
    "* **Interaction occurs over time** Interaction is a *process* that evolves over time. Information flow is not instantaneous. Observations must be fused together to update beliefs.\n",
    "\n",
    "### Approach\n",
    "\n",
    "* Inference approach: Model the system's uncertainty over user intentions as a probability distribution, update via Bayes' rule. $P(\\text{intention}|{input})$\n",
    "    * What inputs would we *expect* to see, given hypothesised intentions and their prior likelihood?\n",
    "        * For example, what mouse trajectories would we expect to see, given that a user was pointing a specific icon?\n",
    "    * If still unresolved, provoke a response that will maximise the information gain (change in entropy).\n",
    "        * For example, move one of the two most likely icons and see if the user compensates.\n",
    "\n",
    "We'll look at a **Bayesian** approach to modelling human computer interaction, where we explicitly model what might be going on inside a user's mind and use Bayesian methods to try and perform \"optimal mindreading\". \n",
    "<img src=\"imgs/brain_inference.png\" width=\"70%\">\n",
    "\n",
    "### Models\n",
    "This view on interaction sees user intentions as **unknown values** which are partially observed through inputs. The time series of inputs from the user give a partial, noisy, incomplete view of intention inside the user's head, along with a great deal of superfluous information. \n",
    "\n",
    "We try and infer intention *generative model* which is a simplified representation of intention and how it is mediated and transformed by the world. The stronger model we have available, the more effectively we can infer intention.\n",
    "\n",
    "> In this view, improving interaction (or at least *input*) comes down to more efficiently concentrating probability density where a user wants it. A better pointing device reduces uncertainty faster; a better display helps a user understand how best to target future actions to concentrate belief as desired; a better model of the user intentions concentrates belief with less explicit effort on the part of a user.\n",
    "\n",
    "<img src=\"imgs/contraction_probability.png\" width=\"70%\">\n",
    "\n",
    "#### Partitioning the inferred variables\n",
    "\n",
    "We can further partition the problem. The causes of observed evidence can be factored, for example, into:\n",
    "\n",
    "* **Mind state** The parameters of the intentions that generate the behaviour: what menu option does the user want?\n",
    "* **World state** The parameters of the motor system that generate movement: where is the user's hand?\n",
    "* **Sensor state** The parameters of the sensing system that generates signals: what is the camera matrix?\n",
    "\n",
    "$$P(X_{\\text{intention}}, X_{\\text{motor}}, X_{\\text{sensing}}|Y)$$\n",
    "\n",
    "[Betancourt's article on probabilistic modeling](https://betanalpha.github.io/assets/case_studies/modeling_and_inference.html) expresses these ideas in terms of the \"phenomenon\" (intention), \"environment\" (motor/world system) and \"probe\" (sensing/interface context).\n",
    "\n",
    "##### Purity\n",
    "It's rare to have an interaction loop that is *pure* Bayesian, where every step of the interaction is modelled with probability distributions and updated via Bayesian inference. Often we restrict the Bayesian slice to the realm where uncertainty is most relevant.\n",
    "\n",
    "[DIAGRAM]\n",
    "\n",
    "For example, we might have a system where:\n",
    "\n",
    "* A standard ML algorithm processes high-dimensional sensor data to a simpler form (e.g. a touch sensor to a cursor)\n",
    "* Bayesian inference over possible gestures that could be being performed by the cursor (not the sensor)\n",
    "* A standard state machine which actuates when probabilities cross thresholds.\n",
    "\n",
    "This gives the power of inverse models (e.g. deep nets) in efficiently performing *representation learning*, and the standard and familiar operation of systems with discrete states, but with some of the robustness and flexibility of a Bayesian model. It's not *necessary* to do this; we could have a fully Bayesian interactive system, but it's rarely practical to do so, and it raises questions about how a user might understand and use such a system.\n",
    "\n",
    "### Forward-inverse\n",
    "[FORWARD-INVERSE]\n",
    "In particular, this is a really powerful way of plugging together advanced ML systems (e.g. for computer vision); these are extremely powerful, but typically don't have any representation of uncertainty, or at best a weak one. Instead, most deep learning based systems map directly from one space to another; in interaction this is often a mapping from an observed sensor state (like an image) to an inferred hidden state (like the pose of the person in the image). This is an **inverse model** (because it maps from observations to hidden states); we can also use ML-learned **forward models** (i.e. generative models from hidden states to models) as part of a Bayesian model, learning some elements of the data generating process that we cannot easily write down analytically.\n",
    "\n",
    "### Uncertainty\n",
    "* Input from a human user will often be ambiguous, at least at some point in time. This might be because of:\n",
    "    * Genuine noise in the sensing that disturbs the intended control;\n",
    "    * User confusion, error or changing intentions;\n",
    "    * Partial and incomplete evidence of intention from sensing;\n",
    "    * Inaccurate models of behaviour given intention.\n",
    "* Failure to represent uncertainty means actions might be taken without sufficient evidence, or require unreasonable quantities of evidence to actuate.\n",
    "* Balancing the information flow requires a proper accounting of uncertainty.\n",
    "\n",
    "[DIAGRAM]\n",
    "\n",
    "#### Feedback of uncertainty\n",
    "Uncertainty is useful to perform robust inference. It can also assist users in understanding the belief state of the system they are controlling. Reflecting the probability distribution (or summaries of it) can be a powerful way of building interfaces that help a user understand how their action is being interpreted, and when ambiguity remains.\n",
    "\n",
    "#### Active inference\n",
    "A system which models uncertainty can take actions to minimise it; it's not possible to do this if you don't capture the uncertainty! This means we can build interactive systems that generate stimuli to optimally acquire information (reduce uncertainty). This is the \"pull\" to the \"push\" of uncertainty feedback. A Bayesian interactive system can reveal its probability distribution to help the user feed it the right information, and stimulate the user to feed it the most helpful information. \n",
    "\n",
    "\n",
    "### Priors\n",
    "Typically we have priors that are either derived from:\n",
    "    * observations from a population; for example, we might use historical frequencies of selection of menu items as a prior for the probability of selecting those items\n",
    "    * the immediate past; we use a sequential filtering process where the posterior from one timestep becomes the prior for the next; for example, a language model might predict the next character to enter *given* the previous characters entered.\n",
    "\n",
    "We may also have priors that arise from psychological or physiological models. For example, if we were tracking someone's hand in space, we could use a prior that implemented the reach volume of the hand -- the probability of the hand being more than 2m from the torso is probably small, for example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "We'll look at building a very simple gesture recogniser using a *particle filter* (that's a sample-based/MCMC probabilistic filter).\n",
    "\n",
    "**Link to the notebook: [examples/1_in_the_loop.ipynb](ex_1_in_the_loop.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papers \n",
    "\n",
    "### Paper a: AnglePose\n",
    "1. Rogers, Simon, John Williamson, Craig Stewart, and Roderick Murray-Smith. 2011. **“AnglePose: Robust, Precise Capacitive Touch Tracking via 3d Orientation Estimation.”** In *Proceedings of the 2011 Annual Conference on Human Factors in Computing Systems - CHI ’11*, 2575. Vancouver, BC, Canada: ACM Press. https://doi.org/10.1145/1978942.1979318.\n",
    "\n",
    "![AnglePose](imgs/paper_1_anglepose.png)\n",
    "\n",
    "* **Distribution**\n",
    "    * Over finger poses, i.e. over the 4D vector space $[x,y, \\phi, \\theta]$. Roll is ignored.\n",
    "* **Data Generating Process**\n",
    "    * Simple model of finger as a hinged flap\n",
    "    * Observed via basic capacitive model \n",
    "    * First-order dynamics of motion (e.g. velocity tends to be constant in the short term)\n",
    "* **Priors**\n",
    "    * The previous time step (i.e. the last pose known)\n",
    "    * And the bounds of the device\n",
    "* **Observation**\n",
    "    * Raw sensor images (160 element vectors representing capacitances)\n",
    "* **Inference**\n",
    "    * Sequential Monte Carlo (particle filter) -- propagating samples forward in time.\n",
    "* **Interaction benefit**\n",
    "    * Increased precision and robustness of pointing\n",
    "    * Uncertainty available to decide on whether to actuate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper b: Dasher\n",
    "1. Ward, David J., Alan F. Blackwell, and David JC MacKay. 2000a. **“Dasher-a Data Entry Interface Using Continuous Gestures and Language Models.”** In *UIST*, 129–37.\n",
    "\n",
    "![Dasher](imgs/paper_2_dasher.png)\n",
    "\n",
    "* **Distribution**\n",
    "    * Over (sequences of) characters of an alphabet.\n",
    "* **Data Generating Process**\n",
    "    * Characters are generated by a Markov model (PPM-based) conditioned on prior characters.\n",
    "    * These are indexed based on a response to a stimuli which dedicates screen real-estate according to prior.\n",
    "* **Priors**\n",
    "    * Language model given previous characters    \n",
    "* **Observation**\n",
    "    * Cursor position (note: not stochastic!).\n",
    "* **Inference**\n",
    "    * Exact.\n",
    "* **Interaction benefit**\n",
    "    * Increased efficiency of interaction \n",
    "    * Easy to fuse with other input sources (e.g. SpeechDasher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper c: BIGNav\n",
    "1. Liu, Wanyu, Rafael Lucas d’Oliveira, Michel Beaudouin-Lafon, and Olivier Rioul. 2017a. **“Bignav: Bayesian Information Gain for Guiding Multiscale Navigation.”** In *Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems*, 5869–80. ACM.\n",
    "\n",
    "[FILMSTRIP]\n",
    "\n",
    "* **Distribution**\n",
    "    * Over characters of an alphabet.\n",
    "* **Data Generating Process**\n",
    "    * Characters are generated by a Markov model (PPM-based) conditioned on prior characters.\n",
    "    * These are indexed based on a response to a stimuli which dedicates screen real-estate according to prior.\n",
    "* **Priors**\n",
    "    * Language model given previous characters    \n",
    "* **Observation**\n",
    "    * Cursor position (note: not stochastic!).\n",
    "* **Inference**\n",
    "    * Exact.\n",
    "* **Interaction benefit**\n",
    "    * Increased efficiency of interaction \n",
    "    * Easy to fuse with other input sources (e.g. SpeechDasher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Before: Bayesian optimisation at design time\n",
    "\n",
    "\n",
    "### Motivation\n",
    "Design by hand-engineering relies on idiom and experience, which may not be optimal or agile enough to adapt to new contexts, such as new devices or specific user groups. Automatic optimisation of the specific parameterisation of an interface can address this *but* acquiring data from users to fine-tune is very expensive and very noisy. Bayesian optimisation is a sample-efficient way to tune designs by constructing a distribution over proxy objective functions.\n",
    "\n",
    "#### Approach\n",
    "\n",
    "\n",
    "* Uncertainty: \n",
    "\n",
    "\n",
    "Motivation\n",
    "Diagram\n",
    "### Example\n",
    "### Papers\n",
    "#### Paper a: Engaging games\n",
    "Khajah, Mohammad M, Brett D Roads, Robert V Lindsey, Yun-En Liu, and Michael C Mozer. 2016. **Designing Engaging Games Using Bayesian Optimization.** In *Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems*, 5571–82.\n",
    "\n",
    "#### Paper b: Better fonts\n",
    "Kadner, Florian, Yannik Keller, and Constantin Rothkopf. 2021. **Adaptifont: Increasing Individuals’ Reading Speed with a Generative Font Model and Bayesian Optimization.** In *Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems*, 1–11.\n",
    "\n",
    "#### Paper c: Crowdsourced design\n",
    "Dudley, John J, Jason T Jacques, and Per Ola Kristensson. 2019. **Crowdsourcing Interface Feature Design with Bayesian Optimization.** In *Proceedings of the 2019 Chi Conference on Human Factors in Computing Systems*, 1–12.\n",
    "\n",
    "### Example\n",
    "\n",
    "We'll look at optimising a... using a Gaussian process as a proxy for our objective function with exact inference. This is a simple to apply and widely applicable way of modelling preference or performance functions.\n",
    "\n",
    "**Link to the notebook: [examples/bayesian_optimisation.ipynb](ex_2_bayesian_optimisation.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## After: Bayesian analysis of empirical work\n",
    "### Introduction\n",
    "When we evaluate how an interface works, we typically rely on statistical tools to analyse quantitative results. Even better, we'd hope to use statistical tools to *design* the analyses\n",
    "that we intend to perform: statistics starts before the experiment, not afterwards!\n",
    "\n",
    "Statistical analysis in HCI are common -- just look at any CHI paper -- but they are often inappropriate or flawed. Almost all HCI uses classical frequentists statistics adopted from psychology. Frequentist statistics include things like t-tests, ANOVAs, Mann-Whitney tests, and so on. Frequentist statistics *are not wrong*; they are perfectly mathematically valid and sometimes useful techniques. But they are most certainly not the only way to do statistics and rarely the appropriate methods for HCI.\n",
    "\n",
    "> Some authors (e.g. E. T. Jaynes or Aubrey Clayton) would argue that all of frequentists statistics is useless rubbish and that Bayesian methods are the only valid approach to analysing data. \n",
    "> They might be right. \n",
    "\n",
    "\n",
    "### Motivation\n",
    "Why do frequentist statistics fail to do what we want to do? How do Bayesian methods help? And what are the trade-offs?\n",
    "\n",
    "> Do we want to compare two blocks of observations, apply a \"black box\" algorithm, and make statements about how likely the variation is to be \"random\" as opposed to \"true\"?\n",
    "\n",
    "#### False dichotomy and backwards questions\n",
    "* Frequentist statistics often force us into dichotomous decisions: is A (statistically significantly) better than B. \n",
    "* But *constructing* a B to compare with may not make much sense. At the very least, it leaves make pointwise comparisons to baselines.\n",
    "* This mode of thought permeates how we think about experimental work in HCI **but it is not necessary**.\n",
    "* Dichotomous analyses *are* appropriate if you want to make comparisons to a baseline, in controlled studies, where effects are large and false positives are important.\n",
    "    * For example, in randomised controlled trials for efficacy of drugs.\n",
    "* Frequentist statistics can't answer many questions we'd like to know the answer to; \"how likely is it that A is twice as efficient as B\"? \n",
    "    * **Our analysis procedures should answer the questions we want to know, not define the questions we are allowed to ask!**\n",
    "* Frequentist statistics typically give us a single estimate but not uncertainty about inference.\n",
    "    * FS can make only make uncertainty quantifications about observations, not parameters.\n",
    "    * But our questions are usually about parameters!\n",
    "\n",
    "#### Application and interpretation\n",
    "* Frequentist statistics produce quantities like p-values and confidence intervals. **These are valid but very hard to interpret!**\n",
    "    * Q: define one of these terms *correctly*    \n",
    "\n",
    "* Frequentist statistics are easy to misuse; great care is needed make sure you account for multiple testing, researcher degrees of freedom, stopping rules to preserve the false positive rate of testing procedures.\n",
    "* Frequentist statistics come in pre-packaged forms (e.g. ANOVA). These have to be slotted in. This leads to several problems:\n",
    "    * You must make the choice of approach intelligently among a zoo of tests and procedures. But you cannot adjust any of the details to fit your problem.\n",
    "    * No modelling is required and so you can avoid defining a good data generating process -- which means you are likely to do silly things.\n",
    "* No prior information is explicitly defined. That seems \"objective\", but it hides that every frequentist approach makes *hidden* assumptions equivalent to priors.\n",
    "    * In other words, you get a one-size-fits-all prior that is unlikely to match your true priors, and there is nothing you can do about it.\n",
    "\n",
    "\n",
    "#### Other issues\n",
    "* Frequentist methods are typically used because of tradition. This is not a good reason.\n",
    "    * Bayesian statistics are not widely understood.\n",
    "    * Researchers are reluctant to admit that much of published statistics might be dubious.\n",
    "    * Sotfware and tooling doesn't make it easy to Bayesian analysis.\n",
    "    * Philosophical debates still rage about Bayesian vs. frequentist models. Some are still cautious about Bayesian methods (or aligned with the dark side).\n",
    "* Computational issues used to make Bayesian methods impractical. This isn't a good excuse these days.\n",
    "* Priors can be controversial. You can obviously change what you assume to change what you believe in the light of evidence.\n",
    "    * But the counter-argument is that *expliclity stating* your assumptions (as priors) is the right way to be honest; a procedure can't guarantee honesty but it can hide deception.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Papers\n",
    "#### Paper a: Why Bayesian Statistics Better Fit the Culture and Incentives of HCI\n",
    "Kay, Matthew, Gregory L Nelson, and Eric B Hekler. 2016.\n",
    "**Researcher-Centered Design of Statistics: Why Bayesian Statistics\n",
    "Better Fit the Culture and Incentives of HCI.** In *Proceedings of the\n",
    "2016 CHI Conference on Human Factors in Computing Systems*, 4521–32.\n",
    "\n",
    "##### The problem identified\n",
    "\n",
    "##### The solution suggested\n",
    "\n",
    "##### Why Bayesian?\n",
    "\n",
    "\n",
    "\n",
    "#### Paper b: Prior selection\n",
    "Phelan, Chanda, Jessica Hullman, Matthew Kay, and Paul Resnick. 2019. **Some Prior (s) Experience Necessary: Templates for Getting Started with Bayesian Analysis.** In *Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems*, 1–12.\n",
    "\n",
    "##### The problem identified\n",
    "\n",
    "##### The solution suggested\n",
    "\n",
    "##### Why Bayesian?\n",
    "\n",
    "\n",
    "#### Paper c: Dichotomous-ness\n",
    "Besançon, Lonni, and Pierre Dragicevic. 2019. **The Continued Prevalence of Dichotomous Inferences at CHI.** In *Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems*, 1–11.\n",
    "\n",
    "##### The problem identified\n",
    "\n",
    "##### The solution suggested\n",
    "\n",
    "##### Why Bayesian?\n",
    "\n",
    "### Example\n",
    "\n",
    "### Example\n",
    "\n",
    "We'll look at analysing a ..., from a pre-created dataset. We'll use a simple regression model, using `pymc3` to perform MCMC-based inference. We'll look at how we can interpret and report the results of the inference process.\n",
    "\n",
    "**Link to the notebook: [ex_3_regression_analysis.ipynb](ex_3_regression_analysis.ipynb)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## About: Bayesian models of cognition and behaviour\n",
    "### Introduction\n",
    "How do we start to build interfaces? In the old days, hardware and computational power dictated many of the constraints.\n",
    "![Ye olde interaction experience.]()\n",
    "Even so, ancient mainframes still  had to group their switches logically, label them, and lay them out for ergonomic reachability. \n",
    "To build interfaces we need to understand how humans behave. Human behaviour is the key constraint that defines interaction. We need models of how humans behave. \n",
    "\n",
    "Some HCI relies on human experience of behaviour (\"designer's intuition\"), heuristics that formalise these experiences, and repeated evaluation as a crutch to stitch up the mismatches. Computational interaction rejects this approach, and puts computational models first. This means we have to have actionable simulators of aspects of human behaviour that can be applied to interface design problems.\n",
    "\n",
    "Some human simulation problems are tricky but largely in the realm of the observable and relatively certain, like simulating reach volumes from biomechanics. But others, especially those that involve cognition, are very hard to construct. Cognitive processes are:\n",
    "\n",
    "* weakly observable -- we have essentially no instruments to act upon them and limited modes of observation.\n",
    "* potentially highly variable among the population and even within an individual\n",
    "* Cognition is stochastic in production of evidence (\"same\" mental state => different observed outcomes).\n",
    "* very complex in nature. A linear system probably won't suffice!\n",
    "\n",
    "Diagram\n",
    "\n",
    "### Papers\n",
    "#### Paper a: Models of visualisation\n",
    "Kim, Yea-Seul, Logan A Walls, Peter Krafft, and Jessica Hullman. 2019. **“A Bayesian Cognition Approach to Improve Data Visualization.”** In *Proceedings of the 2019 Chi Conference on Human Factors in Computing Systems*, 1–14.\n",
    "\n",
    "#### Paper b: ABC for cognitive models\n",
    "\n",
    "Kangasrääsiö, Antti, Jussi PP Jokinen, Antti Oulasvirta, Andrew Howes, and Samuel Kaski. 2019. **“Parameter Inference for Computational Cognitive Models with Approximate Bayesian Computation.”** *Cognitive Science* 43 (6): e12738.\n",
    "\n",
    "\n",
    "### Example\n",
    "No example for this section; it's just too much to cover in a short example -- but see Andrew's talk on Wednesday instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With: Interaction with Bayesian models\n",
    "### Introduction\n",
    "Let's turn the tables. What can HCI offer Bayesian modelling? How could HCI help:\n",
    "\n",
    "* create Bayesian models?\n",
    "* validate and verify Bayesian models?\n",
    "* visualise, explore and explain their implications and consequences?\n",
    "\n",
    "> Bayesian modelling is often seen as hard, and the models as complex and inscrutable. This isn't \"really\" true, but\n",
    "> there lots to be done to make the \"real\" complexity manageable. These are problems of interaction between users and models.\n",
    "\n",
    "#### End users\n",
    "\n",
    "\n",
    "Motivation\n",
    "Diagram\n",
    "\n",
    "### Papers\n",
    "#### Paper a: Animation to reveal uncertainty\n",
    "1. Kale, Alex, Francis Nguyen, Matthew Kay, and Jessica Hullman. 2018. **“Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data.”** *IEEE Transactions on Visualization and Computer Graphics* 25 (1): 892–902.\n",
    "#### Paper b: A Bayesian workflow\n",
    "1. Gelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C. Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, and Martin Modrák. 2020. **“Bayesian Workflow.”** *arXiv Preprint arXiv:2011.01808*. https://arxiv.org/abs/2011.01808.\n",
    "\n",
    "### Example\n",
    "\n",
    "**Link to the notebook: [examples/visualisation.ipynb](ex_5_bayesian_visualisation.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
